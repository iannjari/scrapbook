{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPX14R8uFGWcahHgFrxA6ua",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iannjari/scrapbook/blob/main/Clean_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQthghFRZyQA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0mM0W1aaN05"
      },
      "source": [
        "### Import dependencies for data import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX29JAxWdVbf"
      },
      "source": [
        "Un-comment the code cell below to obtain the data. Blocks should be seperated to test whether they're individually working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eorZkAp3aMJh"
      },
      "source": [
        "'''\n",
        "import requests\n",
        "import tarfile\n",
        "from os import path\n",
        "\n",
        "# Downloading the dataset\n",
        "\n",
        "fname = 'airline_2m.tar.gz'\n",
        "url = 'https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/' + fname\n",
        "r = requests.get(url)\n",
        "open(fname , 'wb').write(r.content)\n",
        "\n",
        "# Extracting the dataset\n",
        "tar = tarfile.open(fname)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Verifying the file was extracted properly\n",
        "data_path = \"airline_2m.csv\"\n",
        "path.exists(data_path)\n",
        "\n",
        "import pandas as pd \n",
        "df = pd.read_csv(data_path, encoding = \"ISO-8859-1\",\n",
        "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})\n",
        "df.shape\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEyOZTbbaEmS"
      },
      "source": [
        "Getting the features (these were obtained by reviewing the data by datatype, description from the US DoT(helped remove redudant features) on excel, removing unwanted columns, re-reading the data and converting them to the dictionary below)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6O2EdteEkf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "aab218cc-f6a6-4798-8ad9-4a113a068e68"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "'''path = \"airline_2m.csv\"\n",
        "df = pd.read_csv(path, encoding = \"ISO-8859-1\",\n",
        "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})\n",
        "df.shape'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'path = \"airline_2m.csv\"\\ndf = pd.read_csv(path, encoding = \"ISO-8859-1\",\\n                 dtype={\\'Div1Airport\\': str, \\'Div1TailNum\\': str, \\'Div2Airport\\': str, \\'Div2TailNum\\': str})\\ndf.shape'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtBsxM9NazCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393d1831-c00e-471d-a0a6-4958cf1011cf"
      },
      "source": [
        "featurecols= ['Year','Quarter',\n",
        "'Month','DayofMonth','DayOfWeek','DOT_ID_Reporting_Airline','Flight_Number_Reporting_Airline',\n",
        "'OriginAirportID','OriginState','DestAirportID','DestState','DepTime','Cancelled']\n",
        "featurecols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Year',\n",
              " 'Quarter',\n",
              " 'Month',\n",
              " 'DayofMonth',\n",
              " 'DayOfWeek',\n",
              " 'DOT_ID_Reporting_Airline',\n",
              " 'Flight_Number_Reporting_Airline',\n",
              " 'OriginAirportID',\n",
              " 'OriginState',\n",
              " 'DestAirportID',\n",
              " 'DestState',\n",
              " 'DepTime',\n",
              " 'Cancelled']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxtTvQaejXt"
      },
      "source": [
        "#commmented since featuredata CSV is available featuredata=df[featurecols]\n",
        "'''\n",
        "featuredata=featuredata.dropna()\n",
        "featuredata.to_csv('featuredata.csv',index=False)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJpKOjHGen5G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "dce9a614-40c3-4faf-f9eb-921c44ecc4de"
      },
      "source": [
        "featuredata=pd.read_csv('featuredata.csv')\n",
        "featuredata=featuredata.dropna()\n",
        "featuredata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DOT_ID_Reporting_Airline</th>\n",
              "      <th>Flight_Number_Reporting_Airline</th>\n",
              "      <th>OriginAirportID</th>\n",
              "      <th>OriginState</th>\n",
              "      <th>DestAirportID</th>\n",
              "      <th>DestState</th>\n",
              "      <th>DepTime</th>\n",
              "      <th>Cancelled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>19386</td>\n",
              "      <td>675</td>\n",
              "      <td>13487</td>\n",
              "      <td>MN</td>\n",
              "      <td>14869</td>\n",
              "      <td>UT</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>20437</td>\n",
              "      <td>671</td>\n",
              "      <td>13342</td>\n",
              "      <td>WI</td>\n",
              "      <td>13204</td>\n",
              "      <td>FL</td>\n",
              "      <td>1202.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>20398</td>\n",
              "      <td>3297</td>\n",
              "      <td>11921</td>\n",
              "      <td>CO</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>1644.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>19790</td>\n",
              "      <td>1806</td>\n",
              "      <td>12892</td>\n",
              "      <td>CA</td>\n",
              "      <td>11433</td>\n",
              "      <td>MI</td>\n",
              "      <td>1305.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>20355</td>\n",
              "      <td>465</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>1911.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999995</th>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>19393</td>\n",
              "      <td>966</td>\n",
              "      <td>12889</td>\n",
              "      <td>NV</td>\n",
              "      <td>14107</td>\n",
              "      <td>AZ</td>\n",
              "      <td>1444.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999996</th>\n",
              "      <td>1999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>19704</td>\n",
              "      <td>529</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>945.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999997</th>\n",
              "      <td>2003</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>20355</td>\n",
              "      <td>1457</td>\n",
              "      <td>10994</td>\n",
              "      <td>SC</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999998</th>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>19393</td>\n",
              "      <td>536</td>\n",
              "      <td>13232</td>\n",
              "      <td>IL</td>\n",
              "      <td>10693</td>\n",
              "      <td>TN</td>\n",
              "      <td>1838.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999999</th>\n",
              "      <td>2003</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>19977</td>\n",
              "      <td>1241</td>\n",
              "      <td>12264</td>\n",
              "      <td>VA</td>\n",
              "      <td>13930</td>\n",
              "      <td>IL</td>\n",
              "      <td>1610.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1962970 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Year  Quarter  Month  ...  DestState  DepTime  Cancelled\n",
              "0        1998        1      1  ...         UT   1659.0        0.0\n",
              "1        2009        2      5  ...         FL   1202.0        0.0\n",
              "2        2013        2      6  ...         TX   1644.0        0.0\n",
              "3        2010        3      8  ...         MI   1305.0        0.0\n",
              "4        2006        1      1  ...         NC   1911.0        0.0\n",
              "...       ...      ...    ...  ...        ...      ...        ...\n",
              "1999995  2008        1      3  ...         AZ   1444.0        0.0\n",
              "1999996  1999        1      1  ...         TX    945.0        0.0\n",
              "1999997  2003        4     11  ...         NC   1219.0        0.0\n",
              "1999998  2012        2      5  ...         TN   1838.0        0.0\n",
              "1999999  2003        2      4  ...         IL   1610.0        0.0\n",
              "\n",
              "[1962970 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqZqUmeFeoL1"
      },
      "source": [
        "target_name = \"Cancelled\"\n",
        "target = featuredata[target_name]\n",
        "# note that all features are categorical in nature\n",
        "data = featuredata.drop(columns=[target_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr1i6LsNucpB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    data,target, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzP22cV9eoVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea6bbe2-f6e0-403f-fafb-cb9a9c50443c"
      },
      "source": [
        "target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1962513\n",
              "1.0        457\n",
              "Name: Cancelled, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xpU2qHyjrE6"
      },
      "source": [
        "Class imbalance might be an issue with models modelled on this data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ylOoAqej1Bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44b70c4-725a-4f0e-9bc0-b21431af32bf"
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O91sUMZ0kSHJ"
      },
      "source": [
        "Use a dummy classifier that predicts the majority class always as the base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nou4rhMWj70g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d899cea-8bc1-493c-d359-e786fa3da680"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "dummy_clf.predict(x_test)\n",
        "dummy_clf.score(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997900525023118"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nxyat-kki4w"
      },
      "source": [
        "High accuracy,arising from the imbalanced classes in the target.\n",
        "\n",
        "What's the performance of a logistic regression?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anxlffjVj8EZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ca6a3c-fe06-407f-a8f4-9f10c3f80c6d"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression()\n",
        ")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "cv_results = cross_validate(\n",
        "    logistic_regression, x_train, y_train, cv=10,return_estimator=True)\n",
        "\n",
        "cv_results\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': (Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False)),\n",
              " 'fit_time': array([19.6321888 , 20.35017896, 19.71603346, 20.23547363, 18.55454779,\n",
              "        20.14636874, 19.83860946, 20.95536065, 19.99063611, 19.64264369]),\n",
              " 'score_time': array([0.30624199, 0.32297277, 0.31209469, 0.32347012, 0.31739521,\n",
              "        0.31898522, 0.31893086, 0.31531572, 0.31608129, 0.34043407]),\n",
              " 'test_score': array([0.99975669, 0.99975669, 0.99975669, 0.99975669, 0.99975669,\n",
              "        0.99975669, 0.99975669, 0.99975669, 0.99974909, 0.99975669])}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P47OZyTT0-lI",
        "outputId": "eaa2954d-7d53-48c6-ee26-bf17b8b55864"
      },
      "source": [
        "array=cv_results[\"test_score\"]\n",
        "array.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997559286161598"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3Ghy4Fe4Bz8"
      },
      "source": [
        "Cross-validation score of 99.97 percent\n",
        "\n",
        "How will it perform on unseen data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZliPUqfEj8Hc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac34be1-fb1e-4798-fafa-e1579890bd22"
      },
      "source": [
        "logistic_regression.fit(x_train, y_train)\n",
        "predictions=logistic_regression.predict(x_test)\n",
        "logistic_regression.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997900525023118"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CtR4e_NGvQ_"
      },
      "source": [
        "Look at other metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNsks7sJyRle",
        "outputId": "4bb9e48b-ad18-4a80-8157-a39dc833be32"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c_matrix=confusion_matrix(y_test, predictions)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "\n",
        "precision= tp/(tp+fp)\n",
        "misclassification= (fp+fn)/(tn+fn+tp+fp)\n",
        "f_one=tp/(tp+0.5*(fp+fn))\n",
        "\n",
        "print('Precision=',precision)\n",
        "print('Misclassification=',misclassification)\n",
        "print('F1 score=',f_one)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision= nan\n",
            "Misclassification= 0.00020994749768826193\n",
            "F1 score= 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziF5C1HkyR3i",
        "outputId": "10fb537e-9bf9-4963-9a5c-49b52515ac90"
      },
      "source": [
        "tn,fp,fn,tp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(647645, 0, 136, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6vDhll6yR7K",
        "outputId": "1d56b9a6-32f1-40ef-a6f5-65e59136e238"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    647645\n",
              "1.0       136\n",
              "Name: Cancelled, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a04Vl-pEKiSe"
      },
      "source": [
        "Model learnt to predict most common class due to class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYJppMZmKgm0",
        "outputId": "63e04b4b-17bc-4443-f683-89168f2146a5"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# fit predictor and target \n",
        "\n",
        "x_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "y_ros=pd.DataFrame(y_ros)\n",
        "\n",
        "print('Original dataset shape', y_train.value_counts())\n",
        "print('Resample dataset shape', y_ros.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape 0.0    1314868\n",
            "1.0        321\n",
            "Name: Cancelled, dtype: int64\n",
            "Resample dataset shape 1.0    1314868\n",
            "0.0    1314868\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av4TSmq7LZGO",
        "outputId": "766a813c-2f19-4a7f-a55b-03e6e83d8fd1"
      },
      "source": [
        "logistic_regression2 = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression(max_iter=1000)\n",
        ")\n",
        "\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    logistic_regression2, x_ros, y_ros[0], cv=10,return_estimator=True)\n",
        "\n",
        "cv_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': (Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False)),\n",
              " 'fit_time': array([150.6341629 , 157.29128265, 154.79834342, 154.56870341,\n",
              "        144.30095816, 156.2397418 , 158.41387725, 149.68905354,\n",
              "        148.45845675, 157.93913078]),\n",
              " 'score_time': array([0.98783994, 1.01473951, 0.9644196 , 1.00123   , 1.01102424,\n",
              "        1.01666141, 1.01583457, 1.00626826, 1.01128697, 1.04619837]),\n",
              " 'test_score': array([0.99792755, 0.99797318, 0.99789713, 0.99787431, 0.99777925,\n",
              "        0.99797318, 0.99811768, 0.99784389, 0.99789712, 0.9978705 ])}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZk8ZkyRMdo0",
        "outputId": "50d49b35-ab2f-46fd-fd5a-094572116284"
      },
      "source": [
        "array=cv_results[\"test_score\"]\n",
        "array.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.997915380124723"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9jyD8QPEXD"
      },
      "source": [
        "Cross-validation score of 99.79 percent\n",
        "\n",
        "How will it perform on unseen data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSR6DIJfOkkU",
        "outputId": "c337a7d5-fb11-4d3f-9529-2fd2264cff51"
      },
      "source": [
        "logistic_regression2.fit(x_ros,y_ros[0])\n",
        "predictions=logistic_regression2.predict(x_test)\n",
        "logistic_regression2.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.995901392600277"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmhDerJ5Okuj",
        "outputId": "466ef8a2-1682-474a-e530-828e9c5b206f"
      },
      "source": [
        "c_matrix=confusion_matrix(y_test, predictions)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "precision= tp/(tp+fp)\n",
        "misclassification= (fp+fn)/(tn+fn+tp+fp)\n",
        "f_one=tp/(tp+0.5*(fp+fn))\n",
        "\n",
        "print('Precision=',precision)\n",
        "print('Misclassification=',misclassification)\n",
        "print('F1 score=',f_one)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision= 0.0003966679888932963\n",
            "Misclassification= 0.004098607399723055\n",
            "F1 score= 0.0007527286413248024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ8DhQVlOkyz",
        "outputId": "78de814c-e9f2-448a-94c2-196b8752a336"
      },
      "source": [
        "tp,tn,fp,fn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 645125, 2520, 135)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCAZFF3gZIU5"
      },
      "source": [
        "Try undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ1wsuF2PnSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "9ef96ac4-a5b5-48b3-eae2-3ba21437f4bd"
      },
      "source": [
        "# Training will be done on smaller dataset\n",
        "\n",
        "# Create dataframe from oversampled data\n",
        "df=pd.DataFrame(x_ros)\n",
        "df['target']=y_ros\n",
        "df"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1989</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>19707</td>\n",
              "      <td>52</td>\n",
              "      <td>13303</td>\n",
              "      <td>FL</td>\n",
              "      <td>11433</td>\n",
              "      <td>MI</td>\n",
              "      <td>1915</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>19790</td>\n",
              "      <td>1789</td>\n",
              "      <td>12451</td>\n",
              "      <td>FL</td>\n",
              "      <td>10397</td>\n",
              "      <td>GA</td>\n",
              "      <td>2031</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>20366</td>\n",
              "      <td>4150</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>13296</td>\n",
              "      <td>NH</td>\n",
              "      <td>1958</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>19393</td>\n",
              "      <td>1768</td>\n",
              "      <td>12889</td>\n",
              "      <td>NV</td>\n",
              "      <td>14869</td>\n",
              "      <td>UT</td>\n",
              "      <td>1400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>19805</td>\n",
              "      <td>1958</td>\n",
              "      <td>12892</td>\n",
              "      <td>CA</td>\n",
              "      <td>14771</td>\n",
              "      <td>CA</td>\n",
              "      <td>1900</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629731</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>26</td>\n",
              "      <td>6</td>\n",
              "      <td>20366</td>\n",
              "      <td>2842</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>10781</td>\n",
              "      <td>LA</td>\n",
              "      <td>2019</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629732</th>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>20355</td>\n",
              "      <td>1186</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>10821</td>\n",
              "      <td>MD</td>\n",
              "      <td>1645</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629733</th>\n",
              "      <td>2013</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>19930</td>\n",
              "      <td>153</td>\n",
              "      <td>10299</td>\n",
              "      <td>AK</td>\n",
              "      <td>13970</td>\n",
              "      <td>AK</td>\n",
              "      <td>1755</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629734</th>\n",
              "      <td>2013</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>20398</td>\n",
              "      <td>3039</td>\n",
              "      <td>14783</td>\n",
              "      <td>MO</td>\n",
              "      <td>13930</td>\n",
              "      <td>IL</td>\n",
              "      <td>1713</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629735</th>\n",
              "      <td>2019</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>20378</td>\n",
              "      <td>6003</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>13502</td>\n",
              "      <td>CO</td>\n",
              "      <td>1714</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2629736 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0  1   2   3  4      5     6      7   8      9  10    11  target\n",
              "0        1989  1   1   2  1  19707    52  13303  FL  11433  MI  1915     0.0\n",
              "1        2019  2   5   6  1  19790  1789  12451  FL  10397  GA  2031     0.0\n",
              "2        2018  3   7  29  7  20366  4150  11618  NJ  13296  NH  1958     0.0\n",
              "3        2001  4  11   8  4  19393  1768  12889  NV  14869  UT  1400     0.0\n",
              "4        2003  1   3  31  1  19805  1958  12892  CA  14771  CA  1900     0.0\n",
              "...       ... ..  ..  .. ..    ...   ...    ...  ..    ...  ..   ...     ...\n",
              "2629731  2015  4  12  26  6  20366  2842  11298  TX  10781  LA  2019     1.0\n",
              "2629732  2010  3   8  12  4  20355  1186  11057  NC  10821  MD  1645     1.0\n",
              "2629733  2013  4  12   5  4  19930   153  10299  AK  13970  AK  1755     1.0\n",
              "2629734  2013  4  12  16  1  20398  3039  14783  MO  13930  IL  1713     1.0\n",
              "2629735  2019  2   6  23  7  20378  6003  11298  TX  13502  CO  1714     1.0\n",
              "\n",
              "[2629736 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21HsgSyvp2p4",
        "outputId": "f612ba0e-fa57-42db-99ba-c763db40205f"
      },
      "source": [
        "# Sample data\n",
        "df2=df.sample(n=300000)\n",
        "df2['target'].value_counts()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    150339\n",
              "0.0    149661\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6pkvokpp_9w"
      },
      "source": [
        "x,y = df2.drop(columns=['target']),df2['target']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,stratify=y,random_state=42)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEMQVg76ovjm"
      },
      "source": [
        "Try stacked classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdJvI2xFqGAI"
      },
      "source": [
        "from sklearn.ensemble import (RandomForestClassifier, StackingClassifier, GradientBoostingClassifier)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from  sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKjaYVTDov7t"
      },
      "source": [
        "estimators=[\n",
        "            (\"rf\",RandomForestClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"gb\",GradientBoostingClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"knn\",KNeighborsClassifier(n_neighbors=5))\n",
        "]\n",
        "\n",
        "clf=StackingClassifier(estimators=estimators,final_estimator=LogisticRegression())"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCH8zgAKpCF-",
        "outputId": "41359b9c-8ee5-41e3-b81e-050f12e31343"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), clf\n",
        ")\n",
        "\n",
        "pipeline.fit(x_train,y_train)\n",
        "pipeline.score(x_test,y_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFuiSwg7qNWg",
        "outputId": "0b83d5ea-db55-4003-cb81-fcc62607c2bd"
      },
      "source": [
        "preds=pipeline.predict(x_test)\n",
        "c_matrix=confusion_matrix(y_test, preds)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37415, 0, 0, 37585)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ9ZuXhiqpro",
        "outputId": "e3ce5613-0fa2-4953-9418-b44afebb43af"
      },
      "source": [
        "precision= tp/(tp+fp)\n",
        "misclassification= (fp+fn)/(tn+fn+tp+fp)\n",
        "f_one=tp/(tp+0.5*(fp+fn))\n",
        "\n",
        "print('Precision=',precision)\n",
        "print('Misclassification=',misclassification)\n",
        "print('F1 score=',f_one)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision= 1.0\n",
            "Misclassification= 0.0\n",
            "F1 score= 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWhWgFlD00qO"
      },
      "source": [
        "Save this model in ONNX format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "026ddGfC0xuN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}