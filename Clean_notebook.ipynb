{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQthghFRZyQA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0mM0W1aaN05"
      },
      "source": [
        "### Import dependencies for data import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX29JAxWdVbf"
      },
      "source": [
        "Un-comment the code cell below to obtain the data. Blocks should be seperated to test whether they're individually working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eorZkAp3aMJh"
      },
      "source": [
        "'''\n",
        "import requests\n",
        "import tarfile\n",
        "from os import path\n",
        "\n",
        "# Downloading the dataset\n",
        "\n",
        "fname = 'airline_2m.tar.gz'\n",
        "url = 'https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/' + fname\n",
        "r = requests.get(url)\n",
        "open(fname , 'wb').write(r.content)\n",
        "\n",
        "# Extracting the dataset\n",
        "tar = tarfile.open(fname)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Verifying the file was extracted properly\n",
        "data_path = \"airline_2m.csv\"\n",
        "path.exists(data_path)\n",
        "\n",
        "import pandas as pd \n",
        "df = pd.read_csv(data_path, encoding = \"ISO-8859-1\",\n",
        "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})\n",
        "df.shape\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEyOZTbbaEmS"
      },
      "source": [
        "Getting the features (these were obtained by reviewing the data by datatype, description from the US DoT(helped remove redudant features) on excel, removing unwanted columns, re-reading the data and converting them to the dictionary below)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6O2EdteEkf"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = \"airline_2m.csv\"\n",
        "df = pd.read_csv(path, encoding = \"ISO-8859-1\",\n",
        "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtBsxM9NazCq"
      },
      "source": [
        "featurecols= ['Year','Quarter',\n",
        "'Month','DayofMonth','DayOfWeek','DOT_ID_Reporting_Airline','Flight_Number_Reporting_Airline',\n",
        "'OriginAirportID','OriginState','DestAirportID','DestState','DepTime','Cancelled']\n",
        "featurecols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxtTvQaejXt"
      },
      "source": [
        "#commmented since featuredata CSV is available featuredata=df[featurecols]\n",
        "'''\n",
        "featuredata=featuredata.dropna()\n",
        "featuredata.to_csv('featuredata.csv',index=False)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJpKOjHGen5G"
      },
      "source": [
        "featuredata=pd.read_csv('featuredata.csv')\n",
        "featuredata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqZqUmeFeoL1"
      },
      "source": [
        "target_name = \"Cancelled\"\n",
        "target = featuredata[target_name]\n",
        "# note that all features are categorical in nature\n",
        "data = featuredata.drop(columns=[target_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzP22cV9eoVk"
      },
      "source": [
        "target.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xpU2qHyjrE6"
      },
      "source": [
        "Class imbalance might be an issue with models modelled on this data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ylOoAqej1Bi"
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O91sUMZ0kSHJ"
      },
      "source": [
        "Use a dummy classifier that predicts the majority class always as the base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nou4rhMWj70g"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(data, target)\n",
        "dummy_preds=dummy_clf.predict(data)\n",
        "dummy_clf.predict(data)\n",
        "dummy_clf.score(data, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nxyat-kki4w"
      },
      "source": [
        "High accuracy,arising from the imbalanced classes in the target.\n",
        "\n",
        "What's the performance of a logistic regression?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anxlffjVj8EZ"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression()\n",
        ")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "cv_results = cross_validate(\n",
        "    logistic_regression, data, target, cv=10,return_estimator=True)\n",
        "\n",
        "cv_results\n",
        "\n",
        "array=cv_results[\"test_score\"]\n",
        "array.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZliPUqfEj8Hc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}