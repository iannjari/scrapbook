{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPt5L7+PNlDKgF9+Xsk7j/q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iannjari/scrapbook/blob/main/Clean_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQthghFRZyQA"
      },
      "source": [
        ""
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0mM0W1aaN05"
      },
      "source": [
        "### Import dependencies for data import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX29JAxWdVbf"
      },
      "source": [
        "Un-comment the code cell below to obtain the data. Blocks should be seperated to test whether they're individually working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eorZkAp3aMJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "77b50e93-be65-4422-ba8a-208874dc201d"
      },
      "source": [
        "'''\n",
        "import requests\n",
        "import tarfile\n",
        "from os import path\n",
        "\n",
        "# Downloading the dataset\n",
        "\n",
        "fname = 'airline_2m.tar.gz'\n",
        "url = 'https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/' + fname\n",
        "r = requests.get(url)\n",
        "open(fname , 'wb').write(r.content)\n",
        "\n",
        "# Extracting the dataset\n",
        "tar = tarfile.open(fname)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Verifying the file was extracted properly\n",
        "data_path = \"airline_2m.csv\"\n",
        "path.exists(data_path)\n",
        "\n",
        "import pandas as pd \n",
        "df = pd.read_csv(data_path, encoding = \"ISO-8859-1\",\n",
        "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})\n",
        "df.shape\n",
        "\n",
        "'''"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport requests\\nimport tarfile\\nfrom os import path\\n\\n# Downloading the dataset\\n\\nfname = \\'airline_2m.tar.gz\\'\\nurl = \\'https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/\\' + fname\\nr = requests.get(url)\\nopen(fname , \\'wb\\').write(r.content)\\n\\n# Extracting the dataset\\ntar = tarfile.open(fname)\\ntar.extractall()\\ntar.close()\\n\\n# Verifying the file was extracted properly\\ndata_path = \"airline_2m.csv\"\\npath.exists(data_path)\\n\\nimport pandas as pd \\ndf = pd.read_csv(data_path, encoding = \"ISO-8859-1\",\\n                 dtype={\\'Div1Airport\\': str, \\'Div1TailNum\\': str, \\'Div2Airport\\': str, \\'Div2TailNum\\': str})\\ndf.shape\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEyOZTbbaEmS"
      },
      "source": [
        "Getting the features (these were obtained by reviewing the data by datatype, description from the US DoT(helped remove redudant features) on excel, removing unwanted columns, re-reading the data and converting them to the dictionary below)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6O2EdteEkf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b00b9abc-78b4-435f-e49e-6c0ee84d7b0e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "'''path = \"airline_2m.csv\"\n",
        "df = pd.read_csv(path, encoding = \"ISO-8859-1\",\n",
        "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})\n",
        "df.shape'''"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'path = \"airline_2m.csv\"\\ndf = pd.read_csv(path, encoding = \"ISO-8859-1\",\\n                 dtype={\\'Div1Airport\\': str, \\'Div1TailNum\\': str, \\'Div2Airport\\': str, \\'Div2TailNum\\': str})\\ndf.shape'"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtBsxM9NazCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e11aeb0-6588-4487-8ecb-d9860973b77c"
      },
      "source": [
        "featurecols= ['Year','Quarter',\n",
        "'Month','DayofMonth','DayOfWeek','DOT_ID_Reporting_Airline','Flight_Number_Reporting_Airline',\n",
        "'OriginAirportID','OriginState','DestAirportID','DestState','DepTime','Cancelled']\n",
        "featurecols"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Year',\n",
              " 'Quarter',\n",
              " 'Month',\n",
              " 'DayofMonth',\n",
              " 'DayOfWeek',\n",
              " 'DOT_ID_Reporting_Airline',\n",
              " 'Flight_Number_Reporting_Airline',\n",
              " 'OriginAirportID',\n",
              " 'OriginState',\n",
              " 'DestAirportID',\n",
              " 'DestState',\n",
              " 'DepTime',\n",
              " 'Cancelled']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxtTvQaejXt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a4a090c-1862-4fec-b751-37c73edc8cec"
      },
      "source": [
        "#commmented since featuredata CSV is available featuredata=df[featurecols]\n",
        "'''\n",
        "featuredata=featuredata.dropna()\n",
        "featuredata.to_csv('featuredata.csv',index=False)\n",
        "'''"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfeaturedata=featuredata.dropna()\\nfeaturedata.to_csv('featuredata.csv',index=False)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJpKOjHGen5G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "a223c6ee-b89c-4c74-f58d-1d99fc62aed5"
      },
      "source": [
        "featuredata=pd.read_csv('featuredata.csv')\n",
        "featuredata=featuredata.dropna()\n",
        "featuredata"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DOT_ID_Reporting_Airline</th>\n",
              "      <th>Flight_Number_Reporting_Airline</th>\n",
              "      <th>OriginAirportID</th>\n",
              "      <th>OriginState</th>\n",
              "      <th>DestAirportID</th>\n",
              "      <th>DestState</th>\n",
              "      <th>DepTime</th>\n",
              "      <th>Cancelled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>19386</td>\n",
              "      <td>675</td>\n",
              "      <td>13487</td>\n",
              "      <td>MN</td>\n",
              "      <td>14869</td>\n",
              "      <td>UT</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>20437</td>\n",
              "      <td>671</td>\n",
              "      <td>13342</td>\n",
              "      <td>WI</td>\n",
              "      <td>13204</td>\n",
              "      <td>FL</td>\n",
              "      <td>1202.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>20398</td>\n",
              "      <td>3297</td>\n",
              "      <td>11921</td>\n",
              "      <td>CO</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>1644.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>19790</td>\n",
              "      <td>1806</td>\n",
              "      <td>12892</td>\n",
              "      <td>CA</td>\n",
              "      <td>11433</td>\n",
              "      <td>MI</td>\n",
              "      <td>1305.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>20355</td>\n",
              "      <td>465</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>1911.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999995</th>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>19393</td>\n",
              "      <td>966</td>\n",
              "      <td>12889</td>\n",
              "      <td>NV</td>\n",
              "      <td>14107</td>\n",
              "      <td>AZ</td>\n",
              "      <td>1444.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999996</th>\n",
              "      <td>1999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>19704</td>\n",
              "      <td>529</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>945.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999997</th>\n",
              "      <td>2003</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>20355</td>\n",
              "      <td>1457</td>\n",
              "      <td>10994</td>\n",
              "      <td>SC</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999998</th>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>19393</td>\n",
              "      <td>536</td>\n",
              "      <td>13232</td>\n",
              "      <td>IL</td>\n",
              "      <td>10693</td>\n",
              "      <td>TN</td>\n",
              "      <td>1838.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999999</th>\n",
              "      <td>2003</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>19977</td>\n",
              "      <td>1241</td>\n",
              "      <td>12264</td>\n",
              "      <td>VA</td>\n",
              "      <td>13930</td>\n",
              "      <td>IL</td>\n",
              "      <td>1610.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1962970 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Year  Quarter  Month  ...  DestState  DepTime  Cancelled\n",
              "0        1998        1      1  ...         UT   1659.0        0.0\n",
              "1        2009        2      5  ...         FL   1202.0        0.0\n",
              "2        2013        2      6  ...         TX   1644.0        0.0\n",
              "3        2010        3      8  ...         MI   1305.0        0.0\n",
              "4        2006        1      1  ...         NC   1911.0        0.0\n",
              "...       ...      ...    ...  ...        ...      ...        ...\n",
              "1999995  2008        1      3  ...         AZ   1444.0        0.0\n",
              "1999996  1999        1      1  ...         TX    945.0        0.0\n",
              "1999997  2003        4     11  ...         NC   1219.0        0.0\n",
              "1999998  2012        2      5  ...         TN   1838.0        0.0\n",
              "1999999  2003        2      4  ...         IL   1610.0        0.0\n",
              "\n",
              "[1962970 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqZqUmeFeoL1"
      },
      "source": [
        "target_name = \"Cancelled\"\n",
        "target = featuredata[target_name]\n",
        "# note that all features are categorical in nature\n",
        "data = featuredata.drop(columns=[target_name])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr1i6LsNucpB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    data,target, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzP22cV9eoVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cedb7724-2b66-475b-eea6-9adbef76146a"
      },
      "source": [
        "target.value_counts()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1962513\n",
              "1.0        457\n",
              "Name: Cancelled, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xpU2qHyjrE6"
      },
      "source": [
        "Class imbalance might be an issue with models modelled on this data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ylOoAqej1Bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00440a26-eeca-4b99-db28-137ff2b90bed"
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O91sUMZ0kSHJ"
      },
      "source": [
        "Use a dummy classifier that predicts the majority class always as the base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nou4rhMWj70g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2068f82c-bbb7-4b73-cb13-f8c496b96c8d"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "dummy_clf.predict(x_test)\n",
        "dummy_clf.score(x_test, y_test)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997900525023118"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nxyat-kki4w"
      },
      "source": [
        "High accuracy,arising from the imbalanced classes in the target.\n",
        "\n",
        "What's the performance of a logistic regression?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anxlffjVj8EZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ae2673-b74c-42bf-9fd1-8244bc904171"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression()\n",
        ")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "cv_results = cross_validate(\n",
        "    logistic_regression, x_train, y_train, cv=10,return_estimator=True)\n",
        "\n",
        "cv_results\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': (Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False)),\n",
              " 'fit_time': array([19.9445858 , 20.39020014, 19.89948249, 20.31958961, 18.6012969 ,\n",
              "        20.11865854, 20.01007533, 21.01506495, 19.83140707, 19.70433259]),\n",
              " 'score_time': array([0.32319236, 0.32811427, 0.31998324, 0.32298279, 0.32017016,\n",
              "        0.3277204 , 0.33705711, 0.33012366, 0.33727789, 0.35032558]),\n",
              " 'test_score': array([0.99975669, 0.99975669, 0.99975669, 0.99975669, 0.99975669,\n",
              "        0.99975669, 0.99975669, 0.99975669, 0.99974909, 0.99975669])}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P47OZyTT0-lI",
        "outputId": "efa404e7-39dd-451a-d32e-15e5725d6f27"
      },
      "source": [
        "array=cv_results[\"test_score\"]\n",
        "array.mean()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997559286161598"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3Ghy4Fe4Bz8"
      },
      "source": [
        "Cross-validation score of 99.97 percent\n",
        "\n",
        "How will it perform on unseen data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZliPUqfEj8Hc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b0be5e-fedc-4996-eb98-18b5191948df"
      },
      "source": [
        "logistic_regression.fit(x_train, y_train)\n",
        "predictions=logistic_regression.predict(x_test)\n",
        "logistic_regression.score(x_test,y_test)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997900525023118"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CtR4e_NGvQ_"
      },
      "source": [
        "Look at other metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNsks7sJyRle",
        "outputId": "a67d36a9-25e1-4d5e-cec0-6a986ee5a27a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c_matrix=confusion_matrix(y_test, predictions)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "\n",
        "precision= tp/(tp+fp)\n",
        "misclassification= (fp+fn)/(tn+fn+tp+fp)\n",
        "f_one=tp/(tp+0.5*(fp+fn))\n",
        "\n",
        "print('Precision=',precision)\n",
        "print('Misclassification=',misclassification)\n",
        "print('F1 score=',f_one)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision= nan\n",
            "Misclassification= 0.00020994749768826193\n",
            "F1 score= 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziF5C1HkyR3i",
        "outputId": "d6c3c53b-5e01-48e2-f7df-b9744d824a82"
      },
      "source": [
        "tn,fp,fn,tp"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(647645, 0, 136, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6vDhll6yR7K",
        "outputId": "8fd6811d-7d2b-4880-c6c5-04900e3d1b89"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    647645\n",
              "1.0       136\n",
              "Name: Cancelled, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a04Vl-pEKiSe"
      },
      "source": [
        "Model learnt to predict most common class due to class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYJppMZmKgm0",
        "outputId": "5cfc1c27-9c43-41b6-80d6-975cce471373"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# fit predictor and target \n",
        "\n",
        "x_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "y_ros=pd.DataFrame(y_ros)\n",
        "\n",
        "print('Original dataset shape', y_train.value_counts())\n",
        "print('Resample dataset shape', y_ros.value_counts())"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape 0.0    1314868\n",
            "1.0        321\n",
            "Name: Cancelled, dtype: int64\n",
            "Resample dataset shape 1.0    1314868\n",
            "0.0    1314868\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av4TSmq7LZGO",
        "outputId": "99c3d8a5-d849-4b81-8748-074684d37959"
      },
      "source": [
        "logistic_regression2 = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression(max_iter=1000)\n",
        ")\n",
        "\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    logistic_regression2, x_ros, y_ros[0], cv=10,return_estimator=True)\n",
        "\n",
        "cv_results"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': (Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False)),\n",
              " 'fit_time': array([148.30363822, 155.39432073, 152.81397343, 151.90520287,\n",
              "        142.49094033, 153.98357606, 156.12010336, 147.68343139,\n",
              "        146.6243453 , 156.22950315]),\n",
              " 'score_time': array([1.00302529, 1.02721572, 1.00263596, 1.02881408, 1.02937269,\n",
              "        1.05268312, 1.06549168, 1.03758383, 1.04081345, 1.08606648]),\n",
              " 'test_score': array([0.99792755, 0.99797318, 0.99789713, 0.99787431, 0.99777925,\n",
              "        0.99797318, 0.99811768, 0.99784389, 0.99789712, 0.9978705 ])}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZk8ZkyRMdo0",
        "outputId": "a19d6fe4-cada-476f-fa16-f30f31156a4e"
      },
      "source": [
        "array=cv_results[\"test_score\"]\n",
        "array.mean()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.997915380124723"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9jyD8QPEXD"
      },
      "source": [
        "Cross-validation score of 99.79 percent\n",
        "\n",
        "How will it perform on unseen data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSR6DIJfOkkU",
        "outputId": "eb2959bd-c688-4443-c79d-cbd915edd28f"
      },
      "source": [
        "logistic_regression2.fit(x_ros,y_ros[0])\n",
        "predictions=logistic_regression2.predict(x_test)\n",
        "logistic_regression2.score(x_test,y_test)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.995901392600277"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmhDerJ5Okuj",
        "outputId": "dd6d83b9-6821-4f01-e8b6-6ac34abdfc98"
      },
      "source": [
        "c_matrix=confusion_matrix(y_test, predictions)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "precision= tp/(tp+fp)\n",
        "misclassification= (fp+fn)/(tn+fn+tp+fp)\n",
        "f_one=tp/(tp+0.5*(fp+fn))\n",
        "\n",
        "print('Precision=',precision)\n",
        "print('Misclassification=',misclassification)\n",
        "print('F1 score=',f_one)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision= 0.0003966679888932963\n",
            "Misclassification= 0.004098607399723055\n",
            "F1 score= 0.0007527286413248024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ8DhQVlOkyz",
        "outputId": "026a5f10-a933-40ec-fa6e-5a97a0b9a8b7"
      },
      "source": [
        "tp,tn,fp,fn"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 645125, 2520, 135)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCAZFF3gZIU5"
      },
      "source": [
        "Try undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ1wsuF2PnSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a6d63672-7169-4756-dc50-fcc7fa12e817"
      },
      "source": [
        "# Training will be done on smaller dataset\n",
        "\n",
        "# Create dataframe from oversampled data\n",
        "df=pd.DataFrame(x_ros)\n",
        "df['target']=y_ros\n",
        "df"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1989</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>19707</td>\n",
              "      <td>52</td>\n",
              "      <td>13303</td>\n",
              "      <td>FL</td>\n",
              "      <td>11433</td>\n",
              "      <td>MI</td>\n",
              "      <td>1915</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>19790</td>\n",
              "      <td>1789</td>\n",
              "      <td>12451</td>\n",
              "      <td>FL</td>\n",
              "      <td>10397</td>\n",
              "      <td>GA</td>\n",
              "      <td>2031</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>20366</td>\n",
              "      <td>4150</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>13296</td>\n",
              "      <td>NH</td>\n",
              "      <td>1958</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>19393</td>\n",
              "      <td>1768</td>\n",
              "      <td>12889</td>\n",
              "      <td>NV</td>\n",
              "      <td>14869</td>\n",
              "      <td>UT</td>\n",
              "      <td>1400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>19805</td>\n",
              "      <td>1958</td>\n",
              "      <td>12892</td>\n",
              "      <td>CA</td>\n",
              "      <td>14771</td>\n",
              "      <td>CA</td>\n",
              "      <td>1900</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629731</th>\n",
              "      <td>2015</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>26</td>\n",
              "      <td>6</td>\n",
              "      <td>20366</td>\n",
              "      <td>2842</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>10781</td>\n",
              "      <td>LA</td>\n",
              "      <td>2019</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629732</th>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>20355</td>\n",
              "      <td>1186</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>10821</td>\n",
              "      <td>MD</td>\n",
              "      <td>1645</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629733</th>\n",
              "      <td>2013</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>19930</td>\n",
              "      <td>153</td>\n",
              "      <td>10299</td>\n",
              "      <td>AK</td>\n",
              "      <td>13970</td>\n",
              "      <td>AK</td>\n",
              "      <td>1755</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629734</th>\n",
              "      <td>2013</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>20398</td>\n",
              "      <td>3039</td>\n",
              "      <td>14783</td>\n",
              "      <td>MO</td>\n",
              "      <td>13930</td>\n",
              "      <td>IL</td>\n",
              "      <td>1713</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2629735</th>\n",
              "      <td>2019</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>20378</td>\n",
              "      <td>6003</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>13502</td>\n",
              "      <td>CO</td>\n",
              "      <td>1714</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2629736 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0  1   2   3  4      5     6      7   8      9  10    11  target\n",
              "0        1989  1   1   2  1  19707    52  13303  FL  11433  MI  1915     0.0\n",
              "1        2019  2   5   6  1  19790  1789  12451  FL  10397  GA  2031     0.0\n",
              "2        2018  3   7  29  7  20366  4150  11618  NJ  13296  NH  1958     0.0\n",
              "3        2001  4  11   8  4  19393  1768  12889  NV  14869  UT  1400     0.0\n",
              "4        2003  1   3  31  1  19805  1958  12892  CA  14771  CA  1900     0.0\n",
              "...       ... ..  ..  .. ..    ...   ...    ...  ..    ...  ..   ...     ...\n",
              "2629731  2015  4  12  26  6  20366  2842  11298  TX  10781  LA  2019     1.0\n",
              "2629732  2010  3   8  12  4  20355  1186  11057  NC  10821  MD  1645     1.0\n",
              "2629733  2013  4  12   5  4  19930   153  10299  AK  13970  AK  1755     1.0\n",
              "2629734  2013  4  12  16  1  20398  3039  14783  MO  13930  IL  1713     1.0\n",
              "2629735  2019  2   6  23  7  20378  6003  11298  TX  13502  CO  1714     1.0\n",
              "\n",
              "[2629736 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21HsgSyvp2p4",
        "outputId": "1390bb1e-70dc-4cc7-8eda-5a6f113b9525"
      },
      "source": [
        "# Sample data\n",
        "df2=df.sample(n=300000)\n",
        "df2['target'].value_counts()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    150041\n",
              "1.0    149959\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6pkvokpp_9w"
      },
      "source": [
        "x,y = df2.drop(columns=['target']),df2['target']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,stratify=y,random_state=42)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEMQVg76ovjm"
      },
      "source": [
        "Try stacked classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdJvI2xFqGAI"
      },
      "source": [
        "from sklearn.ensemble import (RandomForestClassifier, StackingClassifier, GradientBoostingClassifier)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from  sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKjaYVTDov7t"
      },
      "source": [
        "\n",
        "\n",
        "clf=StackingClassifier(estimators==[\n",
        "            (\"rf\",RandomForestClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"gb\",GradientBoostingClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"knn\",KNeighborsClassifier(n_neighbors=5))],final_estimator=LogisticRegression())"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCH8zgAKpCF-",
        "outputId": "35706edb-b979-456b-c3a8-413a6bb28c29"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), StackingClassifier(estimators=[\n",
        "            (\"rf\",RandomForestClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"gb\",GradientBoostingClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"knn\",KNeighborsClassifier(n_neighbors=5))],final_estimator=LogisticRegression()))\n",
        "\n",
        "pipeline.fit(x_train,y_train)\n",
        "pipeline.score(x_test,y_test)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999733333333334"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFuiSwg7qNWg",
        "outputId": "bf944209-41d4-4a76-ec51-d149c89bb7ba"
      },
      "source": [
        "preds=pipeline.predict(x_test)\n",
        "c_matrix=confusion_matrix(y_test, preds)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37508, 2, 0, 37490)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ9ZuXhiqpro",
        "outputId": "8adb2203-132b-4c77-d80f-ad6ef7f032e6"
      },
      "source": [
        "precision= tp/(tp+fp)\n",
        "misclassification= (fp+fn)/(tn+fn+tp+fp)\n",
        "f_one=tp/(tp+0.5*(fp+fn))\n",
        "\n",
        "print('Precision=',precision)\n",
        "print('Misclassification=',misclassification)\n",
        "print('F1 score=',f_one)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision= 0.9999466552864611\n",
            "Misclassification= 2.6666666666666667e-05\n",
            "F1 score= 0.999973326931797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWhWgFlD00qO"
      },
      "source": [
        "Save this model in ONNX format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnzkDG_v2ob2",
        "outputId": "485e036d-d6e0-4d93-8a55-88aa710597ce"
      },
      "source": [
        "pip install skl2onnx"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skl2onnx in /usr/local/lib/python3.7/dist-packages (1.10.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (3.17.3)\n",
            "Requirement already satisfied: onnx>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (1.10.1)\n",
            "Requirement already satisfied: onnxconverter-common>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (0.22.2.post1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.2.1->skl2onnx) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.2.1->skl2onnx) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19->skl2onnx) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAeqAPUL3Wbf",
        "outputId": "b4c3e5ad-ee6b-4b75-eb57-f389b9959c5f"
      },
      "source": [
        "x_train.columns=featurecols[:-1]\n",
        "x_train.to_numpy()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2009, 1, 1, ..., 11292, 'CO', 544.0],\n",
              "       [1989, 1, 3, ..., 10599, 'AL', 1854.0],\n",
              "       [2016, 3, 8, ..., 15380, 'MI', 2015.0],\n",
              "       ...,\n",
              "       [2020, 1, 1, ..., 13931, 'VA', 2319.0],\n",
              "       [2006, 2, 5, ..., 10397, 'GA', 930.0],\n",
              "       [2010, 2, 4, ..., 14869, 'UT', 723.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "026ddGfC0xuN",
        "outputId": "7b2d6e5d-21e0-429a-f558-870e689d6f4f"
      },
      "source": [
        "import skl2onnx \n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
        "\n",
        "\n",
        "\n",
        "initial_types =  [('feature_input', FloatTensorType([None, 8])),\n",
        "                  ('feature_input', StringTensorType([None,1])),\n",
        "                  ('feature_input', FloatTensorType([None, 1])),\n",
        "                  ('feature_input', StringTensorType([None,1])),\n",
        "                  ('feature_input', FloatTensorType([None, 1]))]\n",
        "\n",
        "onx = convert_sklearn(pipeline,initial_types=initial_types)\n",
        "\n",
        "with open(\"stacked_clf.onnx\", \"wb\") as f:\n",
        "    f.write(onx.SerializeToString())"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-012470bba8dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                   ('feature_input', FloatTensorType([None, 1]))]\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0monx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stacked_clf.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/convert.py\u001b[0m in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, verbose)\u001b[0m\n\u001b[1;32m    184\u001b[0m     onnx_model = convert_topology(\n\u001b[1;32m    185\u001b[0m         \u001b[0mtopology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_opset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         remove_identity=not intermediate, verbose=verbose)\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[convert_sklearn] end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, channel_first_inputs, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;31m# Traverse the graph from roots to leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;31m# This loop could eventually be parallelized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m     \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_operators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m     \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_topological_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_shape_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                     \u001b[0;31m# If an operator contains a sequence of operators,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mcall_converter\u001b[0;34m(self, operator, container, verbose)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \"\".join(str(i.is_fed) for i in operator.outputs)))\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscopes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Conv] end - %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_registration.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_operator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_allowed_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_operator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_allowed_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/operator_converters/nearest_neighbours.py\u001b[0m in \u001b[0;36mconvert_nearest_neighbors_classifier\u001b[0;34m(scope, operator, container)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0morder\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0melements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \"\"\"\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0mmany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwei\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m___\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmany\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/operator_converters/nearest_neighbours.py\u001b[0m in \u001b[0;36m_convert_nearest_neighbors\u001b[0;34m(operator, container, k, radius)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mop_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'optim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             **distance_kwargs)\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mtop_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/operator_converters/nearest_neighbours.py\u001b[0m in \u001b[0;36monnx_nearest_neighbors_indices_k\u001b[0;34m(X, Y, k, metric, dtype, op_version, keep_distances, optim, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                           \u001b[0mop_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                           \u001b[0mdim_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                           **kwargs_dist)\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown optimisation '{}'.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/algebra/complex_functions.py\u001b[0m in \u001b[0;36monnx_cdist\u001b[0;34m(XA, XB, metric, dtype, op_version, dim_in, dim_out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         res = _onnx_cdist_sqeuclidean(\n\u001b[1;32m     85\u001b[0m             \u001b[0mXA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             dim_in=dim_in, dim_out=dim_out)\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mOnnxSqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'minkowski'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/algebra/complex_functions.py\u001b[0m in \u001b[0;36m_onnx_cdist_sqeuclidean\u001b[0;34m(XA, XB, dtype, op_version, dim_in, dim_out, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOnnxIdentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scan_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     return _onnx_cdist_end(XA, XB, id_next, flat, dtype, op_version,\n\u001b[0;32m--> 145\u001b[0;31m                            dim_in=dim_in, dim_out=dim_out, **kwargs)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/algebra/complex_functions.py\u001b[0m in \u001b[0;36m_onnx_cdist_end\u001b[0;34m(XA, XB, id_next, flat, dtype, op_version, dim_in, dim_out, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m     node = OnnxScan(XA, XB, output_names=['u(scan0)', 'u(scan1)'],\n\u001b[1;32m    127\u001b[0m                     \u001b[0mnum_scan_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscan_body\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                     op_version=op_version)\n\u001b[0m\u001b[1;32m    129\u001b[0m     return OnnxTranspose(node[1], perm=[1, 0], op_version=op_version,\n\u001b[1;32m    130\u001b[0m                          **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/algebra/onnx_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;34m\"OnnxOperator, OnnxOperatorItem, numpy.ndarray, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \"coo_matrix).\" % (\n\u001b[0;32m--> 106\u001b[0;31m                         type(a), i, class_name))\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mOnnxOperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unexpected type <class 'scipy.sparse.csr.csr_matrix'> for input 1 of operator 'OnnxScan'. It must be an instance of Variable (or a string), OnnxOperator, OnnxOperatorItem, numpy.ndarray, coo_matrix)."
          ]
        }
      ]
    }
  ]
}