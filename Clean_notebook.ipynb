{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPMe2u5Mm2grCa1wT71kKqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iannjari/scrapbook/blob/main/Clean_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQthghFRZyQA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0mM0W1aaN05"
      },
      "source": [
        "### Import dependencies for data import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX29JAxWdVbf"
      },
      "source": [
        "Un-comment the code cell below to obtain the data. Blocks should be seperated to test whether they're individually working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eorZkAp3aMJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ec86c687-1a56-46f0-a46b-a439c2c4ec8d"
      },
      "source": [
        "'''\n",
        "import requests\n",
        "import tarfile\n",
        "from os import path\n",
        "\n",
        "# Downloading the dataset\n",
        "\n",
        "fname = 'airline_2m.tar.gz'\n",
        "url = 'https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/' + fname\n",
        "r = requests.get(url)\n",
        "open(fname , 'wb').write(r.content)\n",
        "\n",
        "# Extracting the dataset\n",
        "tar = tarfile.open(fname)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Verifying the file was extracted properly\n",
        "data_path = \"airline_2m.csv\"\n",
        "path.exists(data_path)\n",
        "\n",
        "import pandas as pd \n",
        "df = pd.read_csv(data_path, encoding = \"ISO-8859-1\",\n",
        "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})\n",
        "df.shape\n",
        "\n",
        "'''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport requests\\nimport tarfile\\nfrom os import path\\n\\n# Downloading the dataset\\n\\nfname = \\'airline_2m.tar.gz\\'\\nurl = \\'https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/\\' + fname\\nr = requests.get(url)\\nopen(fname , \\'wb\\').write(r.content)\\n\\n# Extracting the dataset\\ntar = tarfile.open(fname)\\ntar.extractall()\\ntar.close()\\n\\n# Verifying the file was extracted properly\\ndata_path = \"airline_2m.csv\"\\npath.exists(data_path)\\n\\nimport pandas as pd \\ndf = pd.read_csv(data_path, encoding = \"ISO-8859-1\",\\n                 dtype={\\'Div1Airport\\': str, \\'Div1TailNum\\': str, \\'Div2Airport\\': str, \\'Div2TailNum\\': str})\\ndf.shape\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEyOZTbbaEmS"
      },
      "source": [
        "Getting the features (these were obtained by reviewing the data by datatype, description from the US DoT(helped remove redudant features) on excel, removing unwanted columns, re-reading the data and converting them to the dictionary below)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6O2EdteEkf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e96018b1-6e0e-4996-d592-331099fc9696"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "'''path = \"airline_2m.csv\"\n",
        "df = pd.read_csv(path, encoding = \"ISO-8859-1\",\n",
        "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})\n",
        "df.shape'''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'path = \"airline_2m.csv\"\\ndf = pd.read_csv(path, encoding = \"ISO-8859-1\",\\n                 dtype={\\'Div1Airport\\': str, \\'Div1TailNum\\': str, \\'Div2Airport\\': str, \\'Div2TailNum\\': str})\\ndf.shape'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtBsxM9NazCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f856898-cbf3-428d-d6c6-878e5d4e8c97"
      },
      "source": [
        "featurecols= ['Year','Quarter',\n",
        "'Month','DayofMonth','DayOfWeek','DOT_ID_Reporting_Airline','Flight_Number_Reporting_Airline',\n",
        "'OriginAirportID','OriginState','DestAirportID','DestState','DepTime','Cancelled']\n",
        "featurecols"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Year',\n",
              " 'Quarter',\n",
              " 'Month',\n",
              " 'DayofMonth',\n",
              " 'DayOfWeek',\n",
              " 'DOT_ID_Reporting_Airline',\n",
              " 'Flight_Number_Reporting_Airline',\n",
              " 'OriginAirportID',\n",
              " 'OriginState',\n",
              " 'DestAirportID',\n",
              " 'DestState',\n",
              " 'DepTime',\n",
              " 'Cancelled']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycxtTvQaejXt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd052d91-15fb-42d4-f2a4-23168d74f53a"
      },
      "source": [
        "#commmented since featuredata CSV is available featuredata=df[featurecols]\n",
        "'''\n",
        "featuredata=featuredata.dropna()\n",
        "featuredata.to_csv('featuredata.csv',index=False)\n",
        "'''"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfeaturedata=featuredata.dropna()\\nfeaturedata.to_csv('featuredata.csv',index=False)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJpKOjHGen5G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "96b3ad8f-89a5-45e9-9fba-f45e2c549993"
      },
      "source": [
        "featuredata=pd.read_csv('featuredata.csv')\n",
        "featuredata=featuredata.dropna()\n",
        "featuredata"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DOT_ID_Reporting_Airline</th>\n",
              "      <th>Flight_Number_Reporting_Airline</th>\n",
              "      <th>OriginAirportID</th>\n",
              "      <th>OriginState</th>\n",
              "      <th>DestAirportID</th>\n",
              "      <th>DestState</th>\n",
              "      <th>DepTime</th>\n",
              "      <th>Cancelled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>19386</td>\n",
              "      <td>675</td>\n",
              "      <td>13487</td>\n",
              "      <td>MN</td>\n",
              "      <td>14869.0</td>\n",
              "      <td>UT</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>20437</td>\n",
              "      <td>671</td>\n",
              "      <td>13342</td>\n",
              "      <td>WI</td>\n",
              "      <td>13204.0</td>\n",
              "      <td>FL</td>\n",
              "      <td>1202.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>20398</td>\n",
              "      <td>3297</td>\n",
              "      <td>11921</td>\n",
              "      <td>CO</td>\n",
              "      <td>11298.0</td>\n",
              "      <td>TX</td>\n",
              "      <td>1644.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>19790</td>\n",
              "      <td>1806</td>\n",
              "      <td>12892</td>\n",
              "      <td>CA</td>\n",
              "      <td>11433.0</td>\n",
              "      <td>MI</td>\n",
              "      <td>1305.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>20355</td>\n",
              "      <td>465</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>11057.0</td>\n",
              "      <td>NC</td>\n",
              "      <td>1911.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492931</th>\n",
              "      <td>1994</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>19805</td>\n",
              "      <td>201</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>13891.0</td>\n",
              "      <td>CA</td>\n",
              "      <td>1244.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492932</th>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>20409</td>\n",
              "      <td>1075</td>\n",
              "      <td>12478</td>\n",
              "      <td>NY</td>\n",
              "      <td>14524.0</td>\n",
              "      <td>VA</td>\n",
              "      <td>1155.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492933</th>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>19805</td>\n",
              "      <td>2495</td>\n",
              "      <td>13930</td>\n",
              "      <td>IL</td>\n",
              "      <td>13198.0</td>\n",
              "      <td>MO</td>\n",
              "      <td>1112.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492934</th>\n",
              "      <td>2003</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>19386</td>\n",
              "      <td>147</td>\n",
              "      <td>13487</td>\n",
              "      <td>MN</td>\n",
              "      <td>11637.0</td>\n",
              "      <td>ND</td>\n",
              "      <td>2218.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492935</th>\n",
              "      <td>2017</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>19393</td>\n",
              "      <td>2194</td>\n",
              "      <td>12892</td>\n",
              "      <td>CA</td>\n",
              "      <td>10397.0</td>\n",
              "      <td>GA</td>\n",
              "      <td>745.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>492936 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Year  Quarter  Month  ...  DestState  DepTime  Cancelled\n",
              "0       1998        1      1  ...         UT   1659.0        0.0\n",
              "1       2009        2      5  ...         FL   1202.0        0.0\n",
              "2       2013        2      6  ...         TX   1644.0        0.0\n",
              "3       2010        3      8  ...         MI   1305.0        0.0\n",
              "4       2006        1      1  ...         NC   1911.0        0.0\n",
              "...      ...      ...    ...  ...        ...      ...        ...\n",
              "492931  1994        4     10  ...         CA   1244.0        0.0\n",
              "492932  2008        1      1  ...         VA   1155.0        0.0\n",
              "492933  2008        1      1  ...         MO   1112.0        0.0\n",
              "492934  2003        3      8  ...         ND   2218.0        0.0\n",
              "492935  2017        3      7  ...         GA    745.0        0.0\n",
              "\n",
              "[492936 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqZqUmeFeoL1"
      },
      "source": [
        "target_name = \"Cancelled\"\n",
        "target = featuredata[target_name]\n",
        "# note that all features are categorical in nature\n",
        "data = featuredata.drop(columns=[target_name])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr1i6LsNucpB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    data,target, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzP22cV9eoVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35132e1-8be5-4de6-d40d-449a80294a08"
      },
      "source": [
        "target.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    492820\n",
              "1.0       116\n",
              "Name: Cancelled, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xpU2qHyjrE6"
      },
      "source": [
        "Class imbalance might be an issue with models modelled on this data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ylOoAqej1Bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b25a1b5e-12e7-468f-f7c8-0eced2cc9ee8"
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O91sUMZ0kSHJ"
      },
      "source": [
        "Use a dummy classifier that predicts the majority class always as the base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nou4rhMWj70g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52288cf1-e611-45e7-b178-e2f65c008447"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "dummy_clf.predict(x_test)\n",
        "dummy_clf.score(x_test, y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999729512076671"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nxyat-kki4w"
      },
      "source": [
        "High accuracy,arising from the imbalanced classes in the target.\n",
        "\n",
        "What's the performance of a logistic regression?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anxlffjVj8EZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998e57fe-c880-4a23-c951-d4928651c525"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression()\n",
        ")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "cv_results = cross_validate(\n",
        "    logistic_regression, x_train, y_train, cv=10,return_estimator=True)\n",
        "\n",
        "cv_results\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': (Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False)),\n",
              " 'fit_time': array([4.51406074, 4.52700758, 4.36912441, 4.64982343, 4.66752911,\n",
              "        4.26132154, 4.37534022, 4.19883418, 4.40502   , 4.18332171]),\n",
              " 'score_time': array([0.13393378, 0.14632392, 0.14371562, 0.13246679, 0.10595226,\n",
              "        0.11492705, 0.15090775, 0.11013651, 0.14587855, 0.14681602]),\n",
              " 'test_score': array([0.99978805, 0.99978805, 0.99978805, 0.99978805, 0.99978805,\n",
              "        0.99975777, 0.99975777, 0.99978805, 0.99978805, 0.99978805])}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P47OZyTT0-lI",
        "outputId": "1564119f-08c2-4a52-a72e-7db2953d47ed"
      },
      "source": [
        "array=cv_results[\"test_score\"]\n",
        "array.mean()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997819946229974"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3Ghy4Fe4Bz8"
      },
      "source": [
        "Cross-validation score of 99.97 percent\n",
        "\n",
        "How will it perform on unseen data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZliPUqfEj8Hc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608fe7c3-814d-4c98-f2fd-ebae30f43f01"
      },
      "source": [
        "logistic_regression.fit(x_train, y_train)\n",
        "predictions=logistic_regression.predict(x_test)\n",
        "logistic_regression.score(x_test,y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999729512076671"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CtR4e_NGvQ_"
      },
      "source": [
        "Look at other metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNsks7sJyRle",
        "outputId": "a75e9c5a-c749-48b0-f91f-1385453d65f0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c_matrix=confusion_matrix(y_test, predictions)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "\n",
        "precision= tp/(tp+fp)\n",
        "misclassification= (fp+fn)/(tn+fn+tp+fp)\n",
        "f_one=tp/(tp+0.5*(fp+fn))\n",
        "\n",
        "print('Precision=',precision)\n",
        "print('Misclassification=',misclassification)\n",
        "print('F1 score=',f_one)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision= nan\n",
            "Misclassification= 0.00027048792332896865\n",
            "F1 score= 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziF5C1HkyR3i",
        "outputId": "a91a2b65-96b9-4ec2-9e48-324a50a5e7d9"
      },
      "source": [
        "tn,fp,fn,tp"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(162625, 0, 44, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6vDhll6yR7K",
        "outputId": "c2b452d3-c86a-4447-c17f-a1b8fce91f87"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    162625\n",
              "1.0        44\n",
              "Name: Cancelled, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a04Vl-pEKiSe"
      },
      "source": [
        "Model learnt to predict most common class due to class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYJppMZmKgm0",
        "outputId": "a2244ed1-5b5e-45b5-a65a-6e40a9a1dc77"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# fit predictor and target \n",
        "\n",
        "x_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "y_ros=pd.DataFrame(y_ros)\n",
        "\n",
        "print('Original dataset shape', y_train.value_counts())\n",
        "print('Resample dataset shape', y_ros.value_counts())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape 0.0    330195\n",
            "1.0        72\n",
            "Name: Cancelled, dtype: int64\n",
            "Resample dataset shape 1.0    330195\n",
            "0.0    330195\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av4TSmq7LZGO",
        "outputId": "7e54fa97-eb83-484e-d871-54a5ace37b68"
      },
      "source": [
        "logistic_regression2 = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression(max_iter=1000)\n",
        ")\n",
        "\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    logistic_regression2, x_ros, y_ros[0], cv=10,return_estimator=True)\n",
        "\n",
        "cv_results"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': (Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=1000,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False)),\n",
              " 'fit_time': array([22.11341333, 22.23396945, 23.3046658 , 21.38845372, 22.47447252,\n",
              "        22.33184695, 22.66793299, 20.94541216, 21.17543912, 21.6458528 ]),\n",
              " 'score_time': array([0.31534266, 0.31558299, 0.32684493, 0.32750726, 0.29070592,\n",
              "        0.31225085, 0.32601762, 0.31994963, 0.31512475, 0.31976914]),\n",
              " 'test_score': array([0.99951544, 0.99954572, 0.99930344, 0.99942458, 0.99942458,\n",
              "        0.99940944, 0.99953058, 0.99962144, 0.99945487, 0.99953058])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZk8ZkyRMdo0",
        "outputId": "fba3461a-e9a1-42a5-8539-c4c21e32b7af"
      },
      "source": [
        "array=cv_results[\"test_score\"]\n",
        "array.mean()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9994760671724284"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9jyD8QPEXD"
      },
      "source": [
        "Cross-validation score of 99.79 percent\n",
        "\n",
        "How will it perform on unseen data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSR6DIJfOkkU",
        "outputId": "ef00e120-80a3-46dd-fc21-c0f290021c55"
      },
      "source": [
        "logistic_regression2.fit(x_ros,y_ros[0])\n",
        "predictions=logistic_regression2.predict(x_test)\n",
        "logistic_regression2.score(x_test,y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9988811635898666"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmhDerJ5Okuj",
        "outputId": "91384f96-4c82-424c-c12b-706b6d9383d5"
      },
      "source": [
        "c_matrix=confusion_matrix(y_test, predictions)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "precision= tp/(tp+fp)\n",
        "misclassification= (fp+fn)/(tn+fn+tp+fp)\n",
        "f_one=tp/(tp+0.5*(fp+fn))\n",
        "\n",
        "print('Precision=',precision)\n",
        "print('Misclassification=',misclassification)\n",
        "print('F1 score=',f_one)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision= 0.0\n",
            "Misclassification= 0.0011188364101334613\n",
            "F1 score= 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ8DhQVlOkyz",
        "outputId": "cf8eb856-7bc2-4db3-f9b5-4489de4af531"
      },
      "source": [
        "tp,tn,fp,fn"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 162487, 138, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCAZFF3gZIU5"
      },
      "source": [
        "Try undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ1wsuF2PnSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "66e4c188-f71c-49e1-8abf-4dc24706652a"
      },
      "source": [
        "# Training will be done on smaller dataset\n",
        "\n",
        "# Create dataframe from oversampled data\n",
        "df=pd.DataFrame(x_ros)\n",
        "df['target']=y_ros\n",
        "df"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>19790</td>\n",
              "      <td>2015</td>\n",
              "      <td>10397</td>\n",
              "      <td>GA</td>\n",
              "      <td>12451</td>\n",
              "      <td>FL</td>\n",
              "      <td>1452</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>20366</td>\n",
              "      <td>4909</td>\n",
              "      <td>12448</td>\n",
              "      <td>MS</td>\n",
              "      <td>10397</td>\n",
              "      <td>GA</td>\n",
              "      <td>1928</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>19393</td>\n",
              "      <td>240</td>\n",
              "      <td>12191</td>\n",
              "      <td>TX</td>\n",
              "      <td>13851</td>\n",
              "      <td>OK</td>\n",
              "      <td>827</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>20398</td>\n",
              "      <td>3668</td>\n",
              "      <td>12448</td>\n",
              "      <td>MS</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>827</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>19805</td>\n",
              "      <td>1079</td>\n",
              "      <td>14747</td>\n",
              "      <td>WA</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>1206</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660385</th>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>20304</td>\n",
              "      <td>6275</td>\n",
              "      <td>14747</td>\n",
              "      <td>WA</td>\n",
              "      <td>11884</td>\n",
              "      <td>WA</td>\n",
              "      <td>1259</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660386</th>\n",
              "      <td>2009</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>20363</td>\n",
              "      <td>2453</td>\n",
              "      <td>10577</td>\n",
              "      <td>NY</td>\n",
              "      <td>11433</td>\n",
              "      <td>MI</td>\n",
              "      <td>1711</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660387</th>\n",
              "      <td>2014</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>20355</td>\n",
              "      <td>1910</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>12953</td>\n",
              "      <td>NY</td>\n",
              "      <td>1240</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660388</th>\n",
              "      <td>2012</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>20398</td>\n",
              "      <td>3801</td>\n",
              "      <td>14100</td>\n",
              "      <td>PA</td>\n",
              "      <td>13930</td>\n",
              "      <td>IL</td>\n",
              "      <td>1744</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660389</th>\n",
              "      <td>2015</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>19790</td>\n",
              "      <td>1120</td>\n",
              "      <td>10529</td>\n",
              "      <td>CT</td>\n",
              "      <td>11433</td>\n",
              "      <td>MI</td>\n",
              "      <td>858</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>660390 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0  1   2   3  4      5     6      7   8      9  10    11  target\n",
              "0       2011  4  10  24  1  19790  2015  10397  GA  12451  FL  1452     0.0\n",
              "1       2011  3   7  31  7  20366  4909  12448  MS  10397  GA  1928     0.0\n",
              "2       2010  4  11  19  5  19393   240  12191  TX  13851  OK   827     0.0\n",
              "3       2014  3   9   9  2  20398  3668  12448  MS  11298  TX   827     0.0\n",
              "4       2019  3   9  23  1  19805  1079  14747  WA  11298  TX  1206     0.0\n",
              "...      ... ..  ..  .. ..    ...   ...    ...  ..    ...  ..   ...     ...\n",
              "660385  2010  3   7  30  5  20304  6275  14747  WA  11884  WA  1259     1.0\n",
              "660386  2009  2   6  25  4  20363  2453  10577  NY  11433  MI  1711     1.0\n",
              "660387  2014  1   2  21  5  20355  1910  11057  NC  12953  NY  1240     1.0\n",
              "660388  2012  3   8   9  4  20398  3801  14100  PA  13930  IL  1744     1.0\n",
              "660389  2015  3   9   1  2  19790  1120  10529  CT  11433  MI   858     1.0\n",
              "\n",
              "[660390 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21HsgSyvp2p4",
        "outputId": "d2c58d68-2337-4ca8-ac23-94a408cef37a"
      },
      "source": [
        "# Sample data\n",
        "df2=df.sample(n=300000)\n",
        "df2['target'].value_counts()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    150035\n",
              "0.0    149965\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6pkvokpp_9w"
      },
      "source": [
        "x,y = df2.drop(columns=['target']),df2['target']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,stratify=y,random_state=42)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEMQVg76ovjm"
      },
      "source": [
        "Try stacked classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdJvI2xFqGAI"
      },
      "source": [
        "from sklearn.ensemble import (RandomForestClassifier, StackingClassifier, GradientBoostingClassifier)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from  sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKjaYVTDov7t"
      },
      "source": [
        "\n",
        "\n",
        "clf=StackingClassifier(estimators=[\n",
        "            (\"rf\",RandomForestClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"gb\",GradientBoostingClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"knn\",KNeighborsClassifier(n_neighbors=5))],final_estimator=LogisticRegression())"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCH8zgAKpCF-",
        "outputId": "986251b7-181e-4bf3-cccf-d68469fee95f"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), StackingClassifier(estimators=[\n",
        "            (\"rf\",RandomForestClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"gb\",GradientBoostingClassifier(n_estimators=10,random_state=42)),\n",
        "            (\"knn\",KNeighborsClassifier(n_neighbors=5))],final_estimator=LogisticRegression()))\n",
        "\n",
        "pipeline.fit(x_train,y_train)\n",
        "pipeline.score(x_test,y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99996"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFuiSwg7qNWg",
        "outputId": "5769efc8-6c43-425b-e4f2-e5c79eb6814c"
      },
      "source": [
        "preds=pipeline.predict(x_test)\n",
        "c_matrix=confusion_matrix(y_test, preds)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37488, 3, 0, 37509)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ9ZuXhiqpro",
        "outputId": "98028617-9567-4701-bb42-2583654c01e1"
      },
      "source": [
        "precision= tp/(tp+fp)\n",
        "misclassification= (fp+fn)/(tn+fn+tp+fp)\n",
        "f_one=tp/(tp+0.5*(fp+fn))\n",
        "\n",
        "print('Precision=',precision)\n",
        "print('Misclassification=',misclassification)\n",
        "print('F1 score=',f_one)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision= 0.9999200255918106\n",
            "Misclassification= 4e-05\n",
            "F1 score= 0.9999600111968648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWhWgFlD00qO"
      },
      "source": [
        "Save this model in ONNX format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnzkDG_v2ob2",
        "outputId": "e972bca1-2312-43bd-bb2a-939d2e1e79cd"
      },
      "source": [
        "pip install skl2onnx"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skl2onnx\n",
            "  Downloading skl2onnx-1.10.0-py2.py3-none-any.whl (265 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 265 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (0.22.2.post1)\n",
            "Collecting onnx>=1.2.1\n",
            "  Downloading onnx-1.10.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3 MB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (1.19.5)\n",
            "Collecting onnxconverter-common>=1.7.0\n",
            "  Downloading onnxconverter_common-1.8.1-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from skl2onnx) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.2.1->skl2onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.2.1->skl2onnx) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19->skl2onnx) (1.0.1)\n",
            "Installing collected packages: onnx, onnxconverter-common, skl2onnx\n",
            "Successfully installed onnx-1.10.1 onnxconverter-common-1.8.1 skl2onnx-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAeqAPUL3Wbf",
        "outputId": "ee5c9b6b-224f-4586-950e-44f9e19ab743"
      },
      "source": [
        "x_train.columns=featurecols[:-1]\n",
        "x_train.to_numpy()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1994, 2, 4, ..., 12197.0, 'NY', 1605.0],\n",
              "       [2010, 1, 2, ..., 11503.0, 'CO', 921.0],\n",
              "       [1993, 2, 4, ..., 12339.0, 'IN', 1932.0],\n",
              "       ...,\n",
              "       [1992, 1, 2, ..., 10397.0, 'GA', 1459.0],\n",
              "       [2014, 1, 2, ..., 12953.0, 'NY', 1240.0],\n",
              "       [2010, 3, 7, ..., 11884.0, 'WA', 1259.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "026ddGfC0xuN",
        "outputId": "54edd2c7-a474-4ace-dc7d-2743559cd11b"
      },
      "source": [
        "import skl2onnx \n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
        "\n",
        "\n",
        "\n",
        "initial_types =  [('feature_input', FloatTensorType([None, 10])),\n",
        "                  ('feature_input', StringTensorType([None,2]))]\n",
        "\n",
        "onx = convert_sklearn(pipeline,\n",
        "                      initial_types=\n",
        "                      initial_types)\n",
        "\n",
        "with open(\"stacked_clf.onnx\", \"wb\") as f:\n",
        "    f.write(onx.SerializeToString())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-038247c287ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m onx = convert_sklearn(pipeline,\n\u001b[1;32m     11\u001b[0m                       \u001b[0minitial_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                       initial_types)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stacked_clf.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/convert.py\u001b[0m in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, verbose)\u001b[0m\n\u001b[1;32m    184\u001b[0m     onnx_model = convert_topology(\n\u001b[1;32m    185\u001b[0m         \u001b[0mtopology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_opset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         remove_identity=not intermediate, verbose=verbose)\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[convert_sklearn] end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, channel_first_inputs, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;31m# Traverse the graph from roots to leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;31m# This loop could eventually be parallelized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m     \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_operators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m     \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_topological_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_shape_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                     \u001b[0;31m# If an operator contains a sequence of operators,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mcall_converter\u001b[0;34m(self, operator, container, verbose)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \"\".join(str(i.is_fed) for i in operator.outputs)))\n\u001b[0;32m-> 1015\u001b[0;31m         \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscopes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Conv] end - %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_registration.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_operator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_allowed_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_operator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_allowed_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/operator_converters/one_hot_encoder.py\u001b[0m in \u001b[0;36mconvert_sklearn_one_hot_encoder\u001b[0;34m(scope, operator, container)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                     \u001b[0mci\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'AK'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F02V-N9x7Jx",
        "outputId": "6237ff02-fd25-4727-a50a-aacf47cc8e8f"
      },
      "source": [
        "x_train.info()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 225000 entries, 132065 to 423436\n",
            "Data columns (total 12 columns):\n",
            " #   Column                           Non-Null Count   Dtype \n",
            "---  ------                           --------------   ----- \n",
            " 0   Year                             225000 non-null  object\n",
            " 1   Quarter                          225000 non-null  object\n",
            " 2   Month                            225000 non-null  object\n",
            " 3   DayofMonth                       225000 non-null  object\n",
            " 4   DayOfWeek                        225000 non-null  object\n",
            " 5   DOT_ID_Reporting_Airline         225000 non-null  object\n",
            " 6   Flight_Number_Reporting_Airline  225000 non-null  object\n",
            " 7   OriginAirportID                  225000 non-null  object\n",
            " 8   OriginState                      225000 non-null  object\n",
            " 9   DestAirportID                    225000 non-null  object\n",
            " 10  DestState                        225000 non-null  object\n",
            " 11  DepTime                          225000 non-null  object\n",
            "dtypes: object(12)\n",
            "memory usage: 22.3+ MB\n"
          ]
        }
      ]
    }
  ]
}