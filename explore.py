# -*- coding: utf-8 -*-
"""explore.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14j76CclEUxE4btpxI_l3hA9Q7yPIEN2t
"""

import requests
import tarfile
from os import path

# Downloading the dataset

fname = 'airline_2m.tar.gz'
url = 'https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/' + fname
r = requests.get(url)
open(fname , 'wb').write(r.content)

# Extracting the dataset
tar = tarfile.open(fname)
tar.extractall()
tar.close()

# Verifying the file was extracted properly
data_path = "airline_2m.csv"
path.exists(data_path)

import pandas as pd

df = pd.read_csv(data_path, encoding = "ISO-8859-1",
                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})

df.shape

df.info()





df1=pd.read_csv('cases.csv')
df1

featurecols= pd.Series(df1['Column'])
featurecols

featurecols= ['Year','Quarter',
'Month','DayofMonth','DayOfWeek','DOT_ID_Reporting_Airline','Flight_Number_Reporting_Airline',
'OriginAirportID','OriginState','DestAirportID','DestState','DepTime','Cancelled']
featurecols

featuredata=df[featurecols]
featuredata.to_csv('featuredata.csv',index=False)

featuredata=pd.read_csv('featuredata.csv')
featuredata=featuredata.dropna()
featuredata

target_name = "Cancelled"
target = featuredata[target_name]

data = featuredata.drop(columns=[target_name])

target.value_counts()

data.isnull().values.any()

data





from sklearn.dummy import DummyClassifier
dummy_clf = DummyClassifier(strategy="most_frequent")
dummy_clf.fit(data, target)
dummy_preds=dummy_clf.predict(data)
dummy_clf.predict(data)
dummy_clf.score(data, target)

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LogisticRegression

logistic_regression = make_pipeline(
    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression()
)


from sklearn.model_selection import cross_validate
cv_results = cross_validate(
    logistic_regression, data, target, cv=10,return_estimator=True)

cv_results

array=cv_results["test_score"]
array.mean()

logistic_regression.fit(data,target)
predictions=logistic_regression.predict(data.iloc[0:1])
predictions

data.iloc[0:1]

predictions=logistic_regression.predict(data)
predictions

from sklearn.metrics import confusion_matrix
c_matrix=confusion_matrix(target, predictions)
c_matrix

tn, fp, fn, tp = c_matrix.ravel()
(tn, fp, fn, tp)

precision= tp/(tp+fp)
precision

c_matrix_dummy=confusion_matrix(target, dummy_preds)
tn, fp, fn, tp = c_matrix_dummy.ravel()
(tn, fp, fn, tp)

c_matrix_=confusion_matrix(predictions, dummy_preds)
c_matrix_

y_true = [1,1,1,1,1,1,1]
y_pred = [1,1,1,1,1,1,1]
confusion_matrix(y_true, y_pred)

target.value_counts()

"""Class imbalance is an issue

"""

from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)

# fit predictor and target 

x_ros, y_ros = ros.fit_resample(data, target)

y_ros=pd.DataFrame(y_ros)

print('Original dataset shape', target.value_counts())
print('Resample dataset shape', y_ros.value_counts())

y_ros

logistic_regression = make_pipeline(
    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression()
)


cv_results = cross_validate(
    logistic_regression, x_ros, y_ros[0], cv=10,return_estimator=True)

cv_results

array=cv_results["test_score"]
array.mean()

logistic_regression.fit(x_ros,y_ros[0])
predictions=logistic_regression.predict(x_ros)
c_matrix=confusion_matrix(y_ros, predictions)
tn, fp, fn, tp = c_matrix.ravel()
(tn, fp, fn, tp)

precision= tp/(tp+fp)
precision

from sklearn.ensemble import (RandomForestClassifier, StackingClassifier, GradientBoostingClassifier)
from sklearn.linear_model import LogisticRegression
from  sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

df=pd.DataFrame(x_ros)
df

df['target']=y_ros
df

df2=df.sample(n=300000)
df2['target'].value_counts()

x,y = df2.drop(columns=['target']),df2['target']
x_train, x_test, y_train, y_test = train_test_split(x,y,stratify=y,random_state=42)

estimators=[
            ("rf",RandomForestClassifier(n_estimators=10,random_state=42)),
            ("gb",GradientBoostingClassifier(n_estimators=10,random_state=42)),
            ("knn",KNeighborsClassifier(n_neighbors=5))
]

clf=StackingClassifier(estimators=estimators,final_estimator=LogisticRegression())

pipeline = make_pipeline(
    OneHotEncoder(handle_unknown = 'ignore'), clf
)

pipeline.fit(x_train,y_train)
pipeline.score(x_test,y_test)

y[:100]

preds=pipeline.predict(x[:10000])
c_matrix=confusion_matrix(y[:10000], preds)
tn, fp, fn, tp = c_matrix.ravel()
(tn, fp, fn, tp)

precision= tp/(tp+fp)
precision

accuracy=(tp+tn)/(tp+tn+fn+fp)
accuracy

