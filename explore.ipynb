{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "explore.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "de63ce83"
      },
      "source": [
        "import requests\n",
        "import tarfile\n",
        "from os import path"
      ],
      "id": "de63ce83",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f217c3a",
        "outputId": "c1de56d9-72b3-47c7-d4cc-ee0ea07f665d"
      },
      "source": [
        "# Downloading the dataset\n",
        "\n",
        "fname = 'airline_2m.tar.gz'\n",
        "url = 'https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/' + fname\n",
        "r = requests.get(url)\n",
        "open(fname , 'wb').write(r.content)\n"
      ],
      "id": "1f217c3a",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151681776"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4767e726"
      },
      "source": [
        "# Extracting the dataset\n",
        "tar = tarfile.open(fname)\n",
        "tar.extractall()\n",
        "tar.close()\n"
      ],
      "id": "4767e726",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de866aad",
        "outputId": "9a4ea9ee-b90f-47b6-b24a-199d057c7082"
      },
      "source": [
        "# Verifying the file was extracted properly\n",
        "data_path = \"airline_2m.csv\"\n",
        "path.exists(data_path)"
      ],
      "id": "de866aad",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e07cba7d"
      },
      "source": [
        "import pandas as pd "
      ],
      "id": "e07cba7d",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33735a86"
      },
      "source": [
        "df = pd.read_csv(data_path, encoding = \"ISO-8859-1\",\n",
        "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})"
      ],
      "id": "33735a86",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04af3b34",
        "outputId": "e696b285-2e47-4fb9-c170-79600cce6b38"
      },
      "source": [
        "df.shape"
      ],
      "id": "04af3b34",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000000, 109)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9556731f",
        "outputId": "5d4c946e-487a-4160-bd4d-13cddc942491"
      },
      "source": [
        "df.info()"
      ],
      "id": "9556731f",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000000 entries, 0 to 1999999\n",
            "Columns: 109 entries, Year to Div5TailNum\n",
            "dtypes: float64(72), int64(18), object(19)\n",
            "memory usage: 1.6+ GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2973315",
        "outputId": "c84477e5-d995-4f4e-85a3-802dfe013474"
      },
      "source": [
        "df1=pd.DataFrame()\n",
        "df1['Unique']=pd.DataFrame(df.nunique())\n",
        "df1['Count']=pd.DataFrame(df.count())\n",
        "df1=df1.rename(columns={0: 'Unique'})\n",
        "df1.reset_index()\n",
        "df1"
      ],
      "id": "e2973315",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Year</th>\n",
              "      <td>34</td>\n",
              "      <td>2000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Quarter</th>\n",
              "      <td>4</td>\n",
              "      <td>2000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Month</th>\n",
              "      <td>12</td>\n",
              "      <td>2000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DayofMonth</th>\n",
              "      <td>31</td>\n",
              "      <td>2000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DayOfWeek</th>\n",
              "      <td>7</td>\n",
              "      <td>2000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Div5WheelsOn</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Div5TotalGTime</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Div5LongestGTime</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Div5WheelsOff</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Div5TailNum</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>109 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Unique    Count\n",
              "Year                  34  2000000\n",
              "Quarter                4  2000000\n",
              "Month                 12  2000000\n",
              "DayofMonth            31  2000000\n",
              "DayOfWeek              7  2000000\n",
              "...                  ...      ...\n",
              "Div5WheelsOn           0        0\n",
              "Div5TotalGTime         0        0\n",
              "Div5LongestGTime       0        0\n",
              "Div5WheelsOff          0        0\n",
              "Div5TailNum            0        0\n",
              "\n",
              "[109 rows x 2 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd31f645"
      },
      "source": [
        "#df1.to_csv('cases.csv')"
      ],
      "id": "cd31f645",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bec4a0ac",
        "outputId": "b29bb2d2-58b1-4578-f940-73bfe32d0a67"
      },
      "source": [
        "df1=pd.read_csv('cases.csv')\n",
        "df1"
      ],
      "id": "bec4a0ac",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column</th>\n",
              "      <th>Unique</th>\n",
              "      <th>Count</th>\n",
              "      <th>Categorical?</th>\n",
              "      <th>Needed?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Year</td>\n",
              "      <td>34</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Quarter</td>\n",
              "      <td>4</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Month</td>\n",
              "      <td>12</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DayofMonth</td>\n",
              "      <td>31</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DayOfWeek</td>\n",
              "      <td>7</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DOT_ID_Reporting_Airline</td>\n",
              "      <td>34</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Flight_Number_Reporting_Airline</td>\n",
              "      <td>8050</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>OriginAirportID</td>\n",
              "      <td>407</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>OriginState</td>\n",
              "      <td>53</td>\n",
              "      <td>1999354</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>DestAirportID</td>\n",
              "      <td>409</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DestState</td>\n",
              "      <td>53</td>\n",
              "      <td>1999406</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>DepTime</td>\n",
              "      <td>1436</td>\n",
              "      <td>1963995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Cancelled</td>\n",
              "      <td>2</td>\n",
              "      <td>2000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Column  Unique    Count  Categorical?  Needed?\n",
              "0                              Year      34  2000000           1.0      1.0\n",
              "1                           Quarter       4  2000000           1.0      1.0\n",
              "2                             Month      12  2000000           1.0      1.0\n",
              "3                        DayofMonth      31  2000000           1.0      1.0\n",
              "4                         DayOfWeek       7  2000000           1.0      1.0\n",
              "5          DOT_ID_Reporting_Airline      34  2000000           1.0      1.0\n",
              "6   Flight_Number_Reporting_Airline    8050  2000000           1.0      1.0\n",
              "7                   OriginAirportID     407  2000000           1.0      1.0\n",
              "8                       OriginState      53  1999354           1.0      1.0\n",
              "9                     DestAirportID     409  2000000           1.0      1.0\n",
              "10                        DestState      53  1999406           1.0      1.0\n",
              "11                          DepTime    1436  1963995           NaN      NaN\n",
              "12                        Cancelled       2  2000000           1.0      NaN"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05367f0b",
        "outputId": "94e4694c-7d75-4f09-eb1e-768b1f84a37f"
      },
      "source": [
        "featurecols= pd.Series(df1['Column'])\n",
        "featurecols"
      ],
      "id": "05367f0b",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                Year\n",
              "1                             Quarter\n",
              "2                               Month\n",
              "3                          DayofMonth\n",
              "4                           DayOfWeek\n",
              "5            DOT_ID_Reporting_Airline\n",
              "6     Flight_Number_Reporting_Airline\n",
              "7                     OriginAirportID\n",
              "8                         OriginState\n",
              "9                       DestAirportID\n",
              "10                          DestState\n",
              "11                            DepTime\n",
              "12                          Cancelled\n",
              "Name: Column, dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb33536",
        "outputId": "4e39df83-6ea6-4d74-f7d9-ac250325d301"
      },
      "source": [
        "featurecols= ['Year','Quarter',\n",
        "'Month','DayofMonth','DayOfWeek','DOT_ID_Reporting_Airline','Flight_Number_Reporting_Airline',\n",
        "'OriginAirportID','OriginState','DestAirportID','DestState','DepTime','Cancelled']\n",
        "featurecols"
      ],
      "id": "edb33536",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Year',\n",
              " 'Quarter',\n",
              " 'Month',\n",
              " 'DayofMonth',\n",
              " 'DayOfWeek',\n",
              " 'DOT_ID_Reporting_Airline',\n",
              " 'Flight_Number_Reporting_Airline',\n",
              " 'OriginAirportID',\n",
              " 'OriginState',\n",
              " 'DestAirportID',\n",
              " 'DestState',\n",
              " 'DepTime',\n",
              " 'Cancelled']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7ddee5f"
      },
      "source": [
        "featuredata=df[featurecols]\n",
        "featuredata.to_csv('featuredata.csv',index=False)"
      ],
      "id": "d7ddee5f",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "88f4e16c",
        "outputId": "9ea0c7de-b8e0-4d3c-afa2-33f3949d984c"
      },
      "source": [
        "featuredata=pd.read_csv('featuredata.csv')\n",
        "featuredata=featuredata.dropna()\n",
        "featuredata"
      ],
      "id": "88f4e16c",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DOT_ID_Reporting_Airline</th>\n",
              "      <th>Flight_Number_Reporting_Airline</th>\n",
              "      <th>OriginAirportID</th>\n",
              "      <th>OriginState</th>\n",
              "      <th>DestAirportID</th>\n",
              "      <th>DestState</th>\n",
              "      <th>DepTime</th>\n",
              "      <th>Cancelled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>19386</td>\n",
              "      <td>675</td>\n",
              "      <td>13487</td>\n",
              "      <td>MN</td>\n",
              "      <td>14869</td>\n",
              "      <td>UT</td>\n",
              "      <td>1659.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>20437</td>\n",
              "      <td>671</td>\n",
              "      <td>13342</td>\n",
              "      <td>WI</td>\n",
              "      <td>13204</td>\n",
              "      <td>FL</td>\n",
              "      <td>1202.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>20398</td>\n",
              "      <td>3297</td>\n",
              "      <td>11921</td>\n",
              "      <td>CO</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>1644.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>19790</td>\n",
              "      <td>1806</td>\n",
              "      <td>12892</td>\n",
              "      <td>CA</td>\n",
              "      <td>11433</td>\n",
              "      <td>MI</td>\n",
              "      <td>1305.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>20355</td>\n",
              "      <td>465</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>1911.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999995</th>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>19393</td>\n",
              "      <td>966</td>\n",
              "      <td>12889</td>\n",
              "      <td>NV</td>\n",
              "      <td>14107</td>\n",
              "      <td>AZ</td>\n",
              "      <td>1444.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999996</th>\n",
              "      <td>1999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>19704</td>\n",
              "      <td>529</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>945.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999997</th>\n",
              "      <td>2003</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>20355</td>\n",
              "      <td>1457</td>\n",
              "      <td>10994</td>\n",
              "      <td>SC</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999998</th>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>19393</td>\n",
              "      <td>536</td>\n",
              "      <td>13232</td>\n",
              "      <td>IL</td>\n",
              "      <td>10693</td>\n",
              "      <td>TN</td>\n",
              "      <td>1838.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999999</th>\n",
              "      <td>2003</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>19977</td>\n",
              "      <td>1241</td>\n",
              "      <td>12264</td>\n",
              "      <td>VA</td>\n",
              "      <td>13930</td>\n",
              "      <td>IL</td>\n",
              "      <td>1610.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1962970 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Year  Quarter  Month  ...  DestState  DepTime  Cancelled\n",
              "0        1998        1      1  ...         UT   1659.0        0.0\n",
              "1        2009        2      5  ...         FL   1202.0        0.0\n",
              "2        2013        2      6  ...         TX   1644.0        0.0\n",
              "3        2010        3      8  ...         MI   1305.0        0.0\n",
              "4        2006        1      1  ...         NC   1911.0        0.0\n",
              "...       ...      ...    ...  ...        ...      ...        ...\n",
              "1999995  2008        1      3  ...         AZ   1444.0        0.0\n",
              "1999996  1999        1      1  ...         TX    945.0        0.0\n",
              "1999997  2003        4     11  ...         NC   1219.0        0.0\n",
              "1999998  2012        2      5  ...         TN   1838.0        0.0\n",
              "1999999  2003        2      4  ...         IL   1610.0        0.0\n",
              "\n",
              "[1962970 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6da5386f"
      },
      "source": [
        "target_name = \"Cancelled\"\n",
        "target = featuredata[target_name]\n",
        "\n",
        "data = featuredata.drop(columns=[target_name])"
      ],
      "id": "6da5386f",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "703236ac",
        "outputId": "6d80dced-2798-4ac5-d88e-92483f4f702e"
      },
      "source": [
        "target.value_counts()"
      ],
      "id": "703236ac",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1962513\n",
              "1.0        457\n",
              "Name: Cancelled, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnB8M-8J2X_7",
        "outputId": "dcd4af22-80d3-49db-906d-cdb7a9bfc92e"
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "id": "lnB8M-8J2X_7",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "4db43277",
        "outputId": "0b15f7a5-c66d-4354-c00a-d38c5c44527e"
      },
      "source": [
        "data"
      ],
      "id": "4db43277",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DOT_ID_Reporting_Airline</th>\n",
              "      <th>Flight_Number_Reporting_Airline</th>\n",
              "      <th>OriginAirportID</th>\n",
              "      <th>OriginState</th>\n",
              "      <th>DestAirportID</th>\n",
              "      <th>DestState</th>\n",
              "      <th>DepTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>19386</td>\n",
              "      <td>675</td>\n",
              "      <td>13487</td>\n",
              "      <td>MN</td>\n",
              "      <td>14869</td>\n",
              "      <td>UT</td>\n",
              "      <td>1659.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>20437</td>\n",
              "      <td>671</td>\n",
              "      <td>13342</td>\n",
              "      <td>WI</td>\n",
              "      <td>13204</td>\n",
              "      <td>FL</td>\n",
              "      <td>1202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>6</td>\n",
              "      <td>20398</td>\n",
              "      <td>3297</td>\n",
              "      <td>11921</td>\n",
              "      <td>CO</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>1644.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>19790</td>\n",
              "      <td>1806</td>\n",
              "      <td>12892</td>\n",
              "      <td>CA</td>\n",
              "      <td>11433</td>\n",
              "      <td>MI</td>\n",
              "      <td>1305.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>20355</td>\n",
              "      <td>465</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>1911.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999995</th>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>19393</td>\n",
              "      <td>966</td>\n",
              "      <td>12889</td>\n",
              "      <td>NV</td>\n",
              "      <td>14107</td>\n",
              "      <td>AZ</td>\n",
              "      <td>1444.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999996</th>\n",
              "      <td>1999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>19704</td>\n",
              "      <td>529</td>\n",
              "      <td>11618</td>\n",
              "      <td>NJ</td>\n",
              "      <td>11298</td>\n",
              "      <td>TX</td>\n",
              "      <td>945.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999997</th>\n",
              "      <td>2003</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>20355</td>\n",
              "      <td>1457</td>\n",
              "      <td>10994</td>\n",
              "      <td>SC</td>\n",
              "      <td>11057</td>\n",
              "      <td>NC</td>\n",
              "      <td>1219.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999998</th>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>19393</td>\n",
              "      <td>536</td>\n",
              "      <td>13232</td>\n",
              "      <td>IL</td>\n",
              "      <td>10693</td>\n",
              "      <td>TN</td>\n",
              "      <td>1838.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999999</th>\n",
              "      <td>2003</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>19977</td>\n",
              "      <td>1241</td>\n",
              "      <td>12264</td>\n",
              "      <td>VA</td>\n",
              "      <td>13930</td>\n",
              "      <td>IL</td>\n",
              "      <td>1610.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1962970 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Year  Quarter  Month  ...  DestAirportID  DestState  DepTime\n",
              "0        1998        1      1  ...          14869         UT   1659.0\n",
              "1        2009        2      5  ...          13204         FL   1202.0\n",
              "2        2013        2      6  ...          11298         TX   1644.0\n",
              "3        2010        3      8  ...          11433         MI   1305.0\n",
              "4        2006        1      1  ...          11057         NC   1911.0\n",
              "...       ...      ...    ...  ...            ...        ...      ...\n",
              "1999995  2008        1      3  ...          14107         AZ   1444.0\n",
              "1999996  1999        1      1  ...          11298         TX    945.0\n",
              "1999997  2003        4     11  ...          11057         NC   1219.0\n",
              "1999998  2012        2      5  ...          10693         TN   1838.0\n",
              "1999999  2003        2      4  ...          13930         IL   1610.0\n",
              "\n",
              "[1962970 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRxOpkjA3hvJ"
      },
      "source": [
        ""
      ],
      "id": "lRxOpkjA3hvJ",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7FkMskf5nC6"
      },
      "source": [
        ""
      ],
      "id": "N7FkMskf5nC6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "560225ed",
        "outputId": "4630565b-8b6e-43c9-dbf7-7ca61340e663"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(data, target)\n",
        "dummy_preds=dummy_clf.predict(data)\n",
        "dummy_clf.predict(data)\n",
        "dummy_clf.score(data, target)"
      ],
      "id": "560225ed",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997671895138489"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebcfcb51",
        "outputId": "1c013f8d-060d-4f1f-8982-8c614f0aeb20"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression()\n",
        ")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "cv_results = cross_validate(\n",
        "    logistic_regression, data, target, cv=10,return_estimator=True)\n",
        "\n",
        "cv_results"
      ],
      "id": "ebcfcb51",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': (Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False)),\n",
              " 'fit_time': array([32.69290924, 32.46608949, 30.08179569, 31.75051522, 33.40361786,\n",
              "        33.13747883, 33.03980732, 34.14160705, 34.2582159 , 36.50254631]),\n",
              " 'score_time': array([0.48312211, 0.47943354, 0.49090767, 0.48411751, 0.47259378,\n",
              "        0.45765567, 0.48108029, 0.46795821, 0.48986793, 0.52994537]),\n",
              " 'test_score': array([0.99977076, 0.99977076, 0.99977076, 0.99976566, 0.99976566,\n",
              "        0.99976566, 0.99976566, 0.99976566, 0.99976566, 0.99976566])}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cea40e1",
        "outputId": "ac1f39da-4704-404d-91b5-2f9ab4386b6c"
      },
      "source": [
        "array=cv_results[\"test_score\"]\n",
        "array.mean()"
      ],
      "id": "9cea40e1",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999767189513849"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6b89fe",
        "outputId": "f4107b50-7928-47d2-e514-7df9252e91ae"
      },
      "source": [
        "logistic_regression.fit(data,target)\n",
        "predictions=logistic_regression.predict(data.iloc[0:1])\n",
        "predictions"
      ],
      "id": "7c6b89fe",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7521803",
        "outputId": "3a895ad0-eff2-4c10-ad52-f3380524a58a"
      },
      "source": [
        "data.iloc[0:1]"
      ],
      "id": "d7521803",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DOT_ID_Reporting_Airline</th>\n",
              "      <th>Flight_Number_Reporting_Airline</th>\n",
              "      <th>OriginAirportID</th>\n",
              "      <th>OriginState</th>\n",
              "      <th>DestAirportID</th>\n",
              "      <th>DestState</th>\n",
              "      <th>DepTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>19386</td>\n",
              "      <td>675</td>\n",
              "      <td>13487</td>\n",
              "      <td>MN</td>\n",
              "      <td>14869</td>\n",
              "      <td>UT</td>\n",
              "      <td>1659.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year  Quarter  Month  DayofMonth  DayOfWeek  DOT_ID_Reporting_Airline  \\\n",
              "0  1998        1      1           2          5                     19386   \n",
              "\n",
              "   Flight_Number_Reporting_Airline  OriginAirportID OriginState  \\\n",
              "0                              675            13487          MN   \n",
              "\n",
              "   DestAirportID DestState  DepTime  \n",
              "0          14869        UT   1659.0  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eecbaa53",
        "outputId": "882e3e0d-eefb-4f29-fc4e-5f5b5d8efa5f"
      },
      "source": [
        "predictions=logistic_regression.predict(data)\n",
        "predictions"
      ],
      "id": "eecbaa53",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74036524",
        "outputId": "bc7aa69d-a12a-47e5-bb22-ab6647292088"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c_matrix=confusion_matrix(target, predictions)\n",
        "c_matrix"
      ],
      "id": "74036524",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1951834,   10679],\n",
              "       [      0,     457]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GS8VRmZBBBS",
        "outputId": "750bf2a6-110c-4170-a494-c9240d46e7cd"
      },
      "source": [
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "id": "5GS8VRmZBBBS",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1951834, 10679, 0, 457)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA-dPjMmdIZ5",
        "outputId": "2579e6ca-9270-4b30-ed48-3a7b79044df4"
      },
      "source": [
        "precision= tp/(tp+fp)\n",
        "precision"
      ],
      "id": "RA-dPjMmdIZ5",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04103807471264368"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glGhbROGBnE2",
        "outputId": "6fec2d8f-a479-42cb-da93-3465a48b8c87"
      },
      "source": [
        "c_matrix_dummy=confusion_matrix(target, dummy_preds)\n",
        "tn, fp, fn, tp = c_matrix_dummy.ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "id": "glGhbROGBnE2",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1962513, 0, 457, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAbIZJa9HgPv",
        "outputId": "97fd06cd-b8c5-4030-fba0-3930fec400f8"
      },
      "source": [
        "c_matrix_=confusion_matrix(predictions, dummy_preds)\n",
        "c_matrix_\n"
      ],
      "id": "XAbIZJa9HgPv",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1962970]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jlljWiaH6kU",
        "outputId": "22aea3cb-b550-4ed3-f3e8-3662f9afadfa"
      },
      "source": [
        "y_true = [1,1,1,1,1,1,1]\n",
        "y_pred = [1,1,1,1,1,1,1]\n",
        "confusion_matrix(y_true, y_pred)"
      ],
      "id": "-jlljWiaH6kU",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2WwKQF9JeQj",
        "outputId": "490a58e9-13d4-49ec-9db7-d68f61cc9606"
      },
      "source": [
        "target.value_counts()"
      ],
      "id": "F2WwKQF9JeQj",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1962513\n",
              "1.0        457\n",
              "Name: Cancelled, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-XayzJiLb_U"
      },
      "source": [
        "Class imbalance is an issue\n"
      ],
      "id": "A-XayzJiLb_U"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCEEV3b4MB2K",
        "outputId": "3a595869-53f2-460c-c704-f9d86806c4d4"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# fit predictor and target \n",
        "\n",
        "x_ros, y_ros = ros.fit_resample(data, target)\n",
        "\n",
        "y_ros=pd.DataFrame(y_ros)\n",
        "\n",
        "print('Original dataset shape', target.value_counts())\n",
        "print('Resample dataset shape', y_ros.value_counts())"
      ],
      "id": "HCEEV3b4MB2K",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape 0.0    1962513\n",
            "1.0        457\n",
            "Name: Cancelled, dtype: int64\n",
            "Resample dataset shape 1.0    1962513\n",
            "0.0    1962513\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oY2IdKu1Rhxs",
        "outputId": "5957b3d4-a05f-476a-95fe-fc359bc33068"
      },
      "source": [
        "y_ros"
      ],
      "id": "oY2IdKu1Rhxs",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3925021</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3925022</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3925023</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3925024</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3925025</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3925026 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "0        0.0\n",
              "1        0.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "...      ...\n",
              "3925021  1.0\n",
              "3925022  1.0\n",
              "3925023  1.0\n",
              "3925024  1.0\n",
              "3925025  1.0\n",
              "\n",
              "[3925026 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GQgSgmTME3A",
        "outputId": "93596748-b8c8-44cc-c87b-05136880b6e1"
      },
      "source": [
        "logistic_regression = make_pipeline(\n",
        "    OneHotEncoder(handle_unknown = 'ignore'), LogisticRegression()\n",
        ")\n",
        "\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    logistic_regression, x_ros, y_ros[0], cv=10,return_estimator=True)\n",
        "\n",
        "cv_results"
      ],
      "id": "9GQgSgmTME3A",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': (Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False), Pipeline(memory=None,\n",
              "           steps=[('onehotencoder',\n",
              "                   OneHotEncoder(categories='auto', drop=None,\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 handle_unknown='ignore', sparse=True)),\n",
              "                  ('logisticregression',\n",
              "                   LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                      fit_intercept=True, intercept_scaling=1,\n",
              "                                      l1_ratio=None, max_iter=100,\n",
              "                                      multi_class='auto', n_jobs=None,\n",
              "                                      penalty='l2', random_state=None,\n",
              "                                      solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                      warm_start=False))],\n",
              "           verbose=False)),\n",
              " 'fit_time': array([65.55827451, 66.3100369 , 64.56059337, 63.80581856, 64.08176732,\n",
              "        65.00586033, 63.27556992, 65.5968039 , 65.24255061, 65.4092648 ]),\n",
              " 'score_time': array([1.60839415, 1.4935112 , 1.56556916, 1.64579248, 1.4873445 ,\n",
              "        1.41575527, 1.57723117, 1.48592734, 1.55421305, 1.62598825]),\n",
              " 'test_score': array([0.99679238, 0.9970548 , 0.99673124, 0.99697327, 0.99702168,\n",
              "        0.99686627, 0.99699365, 0.99681276, 0.99713122, 0.996986  ])}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMmc082zR_rl",
        "outputId": "1b8db24f-dbee-46da-e176-31c6ac715c0e"
      },
      "source": [
        "array=cv_results[\"test_score\"]\n",
        "array.mean()"
      ],
      "id": "CMmc082zR_rl",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9969363260723176"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm7qN6pzUvb7",
        "outputId": "c10253ae-97e2-40d0-e332-2d72549d7279"
      },
      "source": [
        "logistic_regression.fit(x_ros,y_ros[0])\n",
        "predictions=logistic_regression.predict(x_ros)\n",
        "c_matrix=confusion_matrix(y_ros, predictions)\n",
        "tn, fp, fn, tp = c_matrix.ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "id": "xm7qN6pzUvb7",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1951834, 10679, 0, 1962513)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU6IaSWoXRXt",
        "outputId": "cd097a69-a928-4ffd-8760-74a4e196cc61"
      },
      "source": [
        "precision= tp/(tp+fp)\n",
        "precision"
      ],
      "id": "UU6IaSWoXRXt",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9945879569752969"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UstHl5FtVIH_"
      },
      "source": [
        ""
      ],
      "id": "UstHl5FtVIH_",
      "execution_count": null,
      "outputs": []
    }
  ]
}